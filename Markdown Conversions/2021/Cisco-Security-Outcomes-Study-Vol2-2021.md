# Security Outcomes Study
## Volume 2
### Maximizing the Top Five Security Practices

## Contents
* [ (Re)Introducing the Fab Five](#reintroducing-the-fab-five)
* [Key Findings](#key-findings)
* [Strategies for Proactive Technology Refresh](#strategies-for-proactive-technology-refresh)
* [Achieving Well-Integrated Security Technologies](#achieving-well-integrated-security-technologies)
* [Developing Threat Detection and Incident Response Capabilities](#developing-threat-detection-and-incident-response-capabilities)
* [Ensuring Prompt Disaster Recovery and Resilience](#ensuring-prompt-disaster-recovery-and-resilience)
* [Conclusion and Recommendations](#conclusion-and-recommendations)
* [About Cisco Secure](#about-cisco-secure)
* [Appendix: Survey Sample Demographics](#appendix-survey-sample-demographics)

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
2

# (Re)Introducing the Fab Five
The 2021 Cisco Security Outcomes Study sought to measure what matters most in cybersecurity 
management. To that end, we examined 25 general security practices and tested how each 
correlates with the achievement of 11 program-level outcomes. You can view these practice-
outcome correlations via an interactive visualization on the 2021 Cisco Security Outcomes Study 
website, or download the full report.

From the testing, we uncovered that five of the 25 practices stood out from the rest in terms of total 
contribution to security program success across all measured outcomes.

In the pages that follow, we focus on these “Fab Five” drivers of security program success to 
identify strategies for maximizing their effectiveness. The “Fab Five” are:

The broad efficacy of these practices 
begs the question, “Why?” What makes 
them so key to unlocking success? What 
factors make them more or less effective? 
How should companies implement these 
practices to maximize outcomes? These 
are the kinds of questions we want to 
explore in this iteration of the Security 
Outcomes Study.

In the pages that follow, we focus on 
these “Fab Five” drivers of security 
program success to identify strategies 
for maximizing their effectiveness. We do 
this through an independently conducted, 
double-blind survey of over 5,
100 IT and 
security professionals around the world. 
We dig into the data, extract salient 
findings, and share vetted takeaways 
to help unlock new heights of security 
achievement for your organization. 

*   **Proactive tech refresh**
    The organization has a proactive tech refresh strategy to 
    stay up-to-date with best available IT and security technologies.
*   **Well-integrated technology**
    Security technologies are well-integrated and work 
    effectively together.
*   **Timely incident response**
    Incident response capabilities enable timely and effective 
    investigation and remediation of security events.
*   **Accurate threat detection**
    Threat detection capabilities provide accurate awareness 
    of potential security events without significant blind spots.
*   **Prompt disaster recovery**
    Recovery capabilities minimize impact and ensure resiliency 
    of business functions affected by security incidents.

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
3

# Key Findings
We asked over 5,
100 IT and security professionals across 27 countries about their organizations’ approaches 
to updating and integrating security architecture, detecting and responding to threats, and staying resilient 
when disaster strikes. As you might imagine, they shared a wide range of insights, struggles, strategies, and 
successes. We analyzed every response in multiple ways, extracting key findings like those featured below.

**Update and integrate architecture**
*   Modern, well-integrated IT contributes 
    to overall program success more than 
    any other security practice or control.
*   Newer, cloud-based architectures 
    are much easier to refresh regularly 
    to keep pace with the business.
*   Organizations that source mainly from 
    a single vendor double their chances 
    of building an integrated tech stack.
*   Integrated security technologies are 
    seven times more likely to achieve 
    high levels of process automation.

**Detect and respond to cyber threats**
*   SecOps programs built on strong 
    people, processes, and technology 
    see a 3.5X performance boost over 
    those with weaker resources.
*   Outsourced detection and response 
    teams are perceived to be superior, 
    but internal teams show faster mean-
    time-to-respond (6 days vs. 13 days).
*   Teams that extensively use 
    threat intelligence are twice as 
    likely to report strong detection 
    and response capabilities.
*   Automation more than doubles 
    the performance of less 
    experienced people, and makes 
    strong teams near certain (95%) 
    to achieve SecOps success.

**Stay resilient when disaster strikes**
*   Organizations with board-level 
    oversight of business continuity 
    and disaster recovery are the 
    most likely (11% above average) to 
    report having strong programs.
*   The probability of maintaining 
    business resilience doesn’t improve 
    until business continuity and 
    disaster recovery capabilities cover 
    at least 80% of critical systems.
*   Organizations that regularly test their 
    business continuity and disaster recovery 
    capabilities in multiple ways are 2.5 times 
    more likely to maintain business resiliency.
*   Organizations that make chaos 
    engineering standard practice 
    are twice as likely to achieve 
    high levels of resiliency.

**About the survey**

*   **Sampling**
    Cisco contracted a survey research 
    firm, YouGov, to field a fully anonymous 
    survey in mid-2021 that utilized a 
    stratified random sampling technique.
*   **Respondents**
    5,123 active IT, security, and privacy 
    professionals from 27 countries 
    responded. Sample demographics can 
    be found in the appendix.
*   **Analysis**
    The Cyentia Institute conducted an 
    independent analysis of the survey 
    data on behalf of Cisco, and generated 
    all results presented in this study.

countries 
responded
5,
1
23
active IT, security, and 
privacy professionals from27

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
4
Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
5

> “We need to know that we’re doing everything 
in our power to keep things secure. We know 
how advanced the attackers are, and they get 
more advanced and have new techniques every 
day. We want to keep our devices, users, and 
company safe, so we want to lower the attack 
surface for any possible security breaches.”
>
> Eric J. Mandela, Assistant Director, 
Technology Infrastructure, Allied Beverage Group

[Read more](link-to-read-more)

Our prior study found that a proactive approach to refreshing and maintaining best-of-breed IT 
and security technologies contributed more to a successful cybersecurity program than any other 
practice. That’s no small feat considering all 25 of the practices we tested are widely considered 
“best practices” in their own right. So, we were keen to dig into what makes this practice so 
effective in this follow-up study.

As we begin digging deeper into tech refresh strategies, let’s do a quick sniff test of the freshness 
of existing infrastructure. We asked respondents what proportion of their active security technologies 

are outdated. On average, 39% of security technologies used by organizations are considered outdated. 
Almost 13% of respondents claim that at least 8 out of 10 security tools they use are showing their age.

This fact alone may help explain a lot of the benefits we see from a proactive tech refresh strategy. 
Ostensibly, newer technologies bring advanced capabilities to bear against an ever-advancing horde of 
cyber threats. But there’s more to it than that, so let’s keep digging into questions we asked of the data.

# Strategies for Proactive Technology Refresh
On average, 39% of security 
technologies used by organizations 
are considered outdated.

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
6

## Do infrastructure traits impact refresh initiatives?
In the original study, we speculated that 
more modern, cloud-based architectures 
might be more effective because they’re 
easier to manage and have native security 
measures built in. As a step toward testing 
that hypothesis, we asked respondents to 

generally describe their tech infrastructure 
by choosing a set of scaled descriptors, 
including:
*   Cloud vs. On-prem
*   Modern vs. Outdated
*   Consolidated vs. Distributed

Do these different architectural traits 
contribute to the efficacy of tech refresh 
capabilities? Very much so, according to 
Figure 1. Organizations with modern, 
consolidated, cloud-based architectures 
are more than twice as likely to report 
strong tech refresh capabilities than 
those using outdated, distributed, on-
prem technologies. Before waving that 
chart around in the next cloud migration 
strategy meeting, however, take note that 
organizations with predominantly on-prem 
environments still perform well above par, 
provided they’ve modernized IT.

Sure, being cloud-native makes it 
easier to unshackle your tech refresh 
strategy, but being outdated is the more 
pressing issue here. When keeping older 
infrastructure fresh becomes an uphill 
battle, you might make more headway 
migrating to a new architecture than 
continuing to retrofit the old. That’s not 
always possible or cost-effective with 
legacy or critical infrastructure, of course, 
but the general principle still applies.

**Figure 1: Effect of IT architecture traits on tech refresh performance**

*   A bar chart showing the percentage of organizations with strong tech refresh capabilities based on their IT environment. The categories are:
    *   Outdated, Distributed, On-Prem: 35.5%
    *   Outdated, Consolidated, On-Prem: 52.5%
    *   Outdated, Distributed, Cloud: 52.9%
    *   Outdated, Consolidated, Cloud: 58.3%
    *   Overall: 58.5%
    *   Modern, Distributed, On-Prem: 65.4%
    *   Modern, Consolidated, On-Prem: 75.1%
    *   Modern, Distributed, Cloud: 73.3%
    *   Modern, Consolidated, Cloud: 81.6%

81
.6%
of organizations with modern, consolidated, 
cloud-based architectures report strong 
tech refresh capabilities

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
7

## Do frequent upgrades help security keep up with business?
According to the 2021 Security Outcomes Study, the outcome most strongly correlated with a proactive tech refresh strategy was 
enabling the security program to keep up with the demands and growth of the business. In fact, that was the strongest practice-
outcome combination across the whole study.

**Figure 2: Effect of tech refresh frequency on the security program’s ability to keep up with business**
*   A bar chart showing the percentage of organizations that are keeping up with business based on the frequency of their tech refresh. The categories are:
    *   Less often than annually: 40%
    *   Annually: 50%
    *   Bi-annually: 60%
    *   Quarterly: 70%
    *   Overall: 51.8%

We asked organizations about the 
frequency of their IT and security 
upgrades, and compared those answers 
to their security program’s stated ability 
to keep up with the business. Is there a 
relationship between those two variables? 
Yes indeed; we found steady improvement 
in this key outcome as the cadence of 
upgrades increased. Overall, organizations 
that upgrade IT and security technologies 
quarterly are about 30% more likely to 
excel at keeping up with the business 
than those who only upgrade every few 
years. Sounds like a good motivational 
poster for stressed IT teams: Keep Current 
and Carry On.

<sup>1</sup> Throughout the report we will label figures with the “Overall” value for a particular practice or outcome. This value represents what the average value is among all respondents who answered that particular 
set of questions. It is provided for reference, and should guide you to understand who is doing better than average, and who is not up to snuff. We are also displaying uncertainty through error bars or 
shaded areas on some charts. When those areas overlap the “Overall” line, it means we can’t infer that particular aspect of a security program has any effect on the outcome or practice we are examining.

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
8

## What (or who) should drive tech refresh efforts?
We’ve established that frequent upgrades contribute to enabling the business, but what — or who — should drive the process 
of getting those upgrades done? We asked respondents to select their organization’s primary drivers for refreshing security 
technologies, and their responses fell into three broad categories: 
*   **Vendor-driven**: Schedule is 
    determined by a SaaS provider or is 
    part of a larger vendor consolidation 
    initiative (most common driver)
*   **Proactive**: On a predetermined 
    schedule or when new features or use 
    cases warrant an upgrade (second 
    most common)
*   **Reactive**: In response to an incident, 
    when tech becomes obsolete, or to 
    satisfy compliance requirements (least 
    common)

These drivers are interesting in and of themselves, but what we really want to know is whether such motives correlated with a stronger 
approach to tech refresh. The answer is found in Figure 3, which basically says that tech refresh initiatives are more successful when 
vendors handle them (or are at least actively involved in making them happen). Less than half of those with a reactive approach 
report strong refresh capabilities, compared to almost two-thirds of those that sync with vendor refresh cycles.

**Figure 3: Effect of primary drivers for upgrades on security tech refresh performance**
*   A bar chart showing the percentage of organizations with strong tech refresh capabilities based on their upgrade strategy. The categories are:
    *   Reactive: 48.9%
    *   Proactive: 52.2%
    *   Vendor-driven: 65.7%
    *   Overall: 58.8%

We get it — this all sounds really suspect 
coming from a vendor of IT and security 
products. But we honestly had zero 
influence on this finding. The survey was 
conducted by an independent, reputable 
research firm, the respondents had no idea 
Cisco sponsored the survey, and the well-
respected Cyentia Institute analyzed the 
data to derive what you see in Figure 3. 
And for good measure, we’ll be extra 
cautious in interpreting these results. 
We suspect much of the improvement 
attributed to vendor-driven approaches 
ties to cloud/SaaS architectures being 
more friendly to frequent upgrades. 
We’ll also note that this may be less 
about vendors being great and more 
about escaping the internal roadblocks 
and political quagmires that tend to 
impede tech refresh schedules.

In the words of Rob Base and DJ E-Z Rock, 
“It takes two to make a thing go right. It 
takes two to make it outta sight.” Who knew 
they were security architects! Make your 
refresh strategy outta sight by harnessing 
the inertia of your technology solution 
partners to drive mission outcomes.

65.
7%
of organizations that sync with 
vendor refresh cycles report 
strong tech refresh capabilities

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
9

## Upgrade for capability or compatibility?
The prior section covered which scenarios prompt organizations to upgrade technologies, and now we’ll look at why they choose one solution 
over another. Figure 4 relays what respondents told us about their selection criteria. Integrating well with existing tech is the clear preference, 
followed by solutions that offer best-of-breed capabilities or that meet particular needs. Perhaps surprisingly, minimizing cost ranks last.

**Figure 4: Primary selection criteria when refreshing security products**
*   A bar chart showing the percentage of organizations that use each selection criteria when refreshing security products. The categories are:
    *   Minimum cost: 8.2%
    *   Baseline compliance: 12.9%
    *   Preferred vendor: 16.6%
    *   Point solutions: 14.1%
    *   Best-of-breed: 30.9%
    *   Ease of integration: 17.3%

That’s all well and good, but does any 
of this matter at all in terms of building a 
successful security program? To answer 
that, we grouped the selection criteria 
from Figure 4 into three categories:
*   **Minimum**: Minimum cost 
    solution; Baseline compliance
*   **Ease of integration**: Integrate with 
    existing tech; Use of preferred vendors
*   **Capability**: Best of breed; 
    Point solutions

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
10

We then tested these categories against an aggregated score created for each organization based on their level of achievement 
across the 11 security outcomes. The absolute value of the score has no particular meaning, but it does provide a point of 
comparison for the different tech refresh strategies. As seen in Figure 5, prioritizing integration and capabilities both drive 
outcomes more than selecting products based on minimizing cost or meeting baseline compliance requirements. But an 
integration-led approach is the only one that significantly outperforms the average.

**Figure 5: Effect of tech selection criterion on overall security outcomes score**
*   A bar chart showing the percentage difference from the mean security outcomes score based on the selection criteria. The categories are:
    *   Minimum: -4.1%
    *   Capability: 0.5%
    *   Integration: 1.6%
    *   Average score: 500

Note that the differences here are pretty small in terms of overall program success. And it’s likely that what we’re really seeing here 
is a window into the broader priorities and practices of the security program. But this does suggest that softer issues like why we 
choose one product over another are worth considering. And if you’re struggling to rank features when refreshing or upgrading 
security solutions, take this as a reasonable justification to push for compatibility and capability over minimizing cost.

### What’s the security outcomes score?
We asked respondents about their organization’s level of success across 12 different 
security program outcomes. The first edition of the Security Outcomes Study 
analyzed these in detail, and you’ll see some of them examined individually in 
this study, too. But we also wanted to create an aggregated score that captures 
each organization’s level of achievement across all 12 outcomes as a measure of 
how the security program is performing overall. We refer to that as the ‘security 
outcomes score,’ and you’ll see it referenced a few times in this report. 

To get the score, we used a fancy statistics technique called “Item Response 
Theory.” This technique enables us to score organizations based on how they’re 
doing across all outcomes, while at the same time accounting for the fact that some 
outcomes might be harder to achieve than others. This tried-and-true technique is 
how standardized test scores are created. The absolute value of the score has no 
particular meaning, but it does provide a point of comparison among programs.

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
11
Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
12

> “CISOs have to be both influencers and educators. If 
we’re going to be as effective as possible, we need 
to be on the leading edge of the strategy decisions 
being made in our organizations. But while we’re 
trying to convince people that security is important, 
that we need the right investments to do it well, and 
that we should be involved in every aspect of the 
business, we must also educate. Most executives 
do not have a background in security, so we need to 
inform them every step of the way about the types of 
risks we’re introducing with each decision we make.”
>
> Helen Patton, Advisory CISO, Cisco  
 @CisoHelen

[Hear Helen’s take on the evolving role of the CISO in 
this intriguing episode of our Security Stories podcast](link-to-podcast)

# Achieving Well-Integrated Security Technologies
According to our last Security Outcomes Study, well-integrated security technologies that work 
effectively with broader IT infrastructure contribute to the likelihood of success for all program 
outcomes. We asked a range of questions designed to dig deeper into the factors behind that 
laudable feat, starting with the intentions behind security tech integrations.

According to respondents, the most common motive for integrating security technologies is to 
improve the efficiency of monitoring and auditing. That resonates with us too, as we’re familiar with 
the pain and frustration of having to check numerous consoles or dashboards to piece together some 
semblance of what’s happening across the network. Easier collaboration and automation were also 
common drivers for integrating security technologies (more on the latter coming up). We tested 
these motivations against reported tech integration levels and program outcomes, but the correlation 
wasn’t that strong. Perhaps “what” or “how” is more important than “why” when integrating security 
technologies? Let’s pull on that thread a little more in the following questions.

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
13

According to respondents, 
the most common motive for 
integrating security technologies 
is to improve the efficiency of 
monitoring and auditing.

## Buy or build for well-integrated tech?
We know from the prior study that integrating security technologies drives outcomes, but what’s the best way to achieve a highly 
integrated tech stack? Buy it that way? Build to suit? Just let it be? Let’s see if we can find out.

We asked organizations about their typical approach to security technology integration, and Figure 6 tallies the responses. Overall, 
more than three-quarters of organizations would rather buy integrated solutions than build them. Of those organizations, over 
40% choose technologies that come with out-of-the-box integrations into their existing infrastructure. And more than 37% take that 
one step further and prefer to source solutions from a single vendor so they’re natively well-integrated or part of a larger platform. 
Just over 20% are willing to build integrations themselves, provided the product fits their needs. Few take a laissez-faire approach.

**Figure 6: Common approaches to security tech integration among all organizations**
*   A bar chart showing the percentage of organizations that use each integration strategy. The categories are:
    *   Nothing extra or special to integrate: 1.3%
    *   Build integrations ourselves as needed: 20.9%
    *   Buy integrated tech from preferred vendors: 37.4%
    *   Buy tech with out-of-the-box integration: 40.3%

3/
4
Overall, more than
of organizations would 
rather buy integrated 
solutions than build them

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
14

Figure 7 evaluates whether any of these integration approaches makes a difference. Here we again see a theme pointing to benefits 
from collaborating with vendors to keep technology modern and well-integrated. As seen in the chart, sticking with a preferred 
vendor is over twice as likely to achieve well-integrated security technologies as a hands-off approach (~69% vs. ~31%). 
Furthermore, according to our research, that finding remains consistent across all organization sizes, though the benefits of using a 
preferred vendor are somewhat higher for small and midsize firms versus large enterprises. 

And yes, we’re aware that’s another suspiciously convenient finding coming from a company with an extensive, integrated security 
portfolio. Sure, we’re pleased to see that this result supports Cisco’s strategy...but recall that this was a double-blind study and we 
didn’t manipulate that result at all.

Not surprisingly, organizations that didn’t do anything extra to integrate security technologies became a self-fulfilling prophecy. 
We do, however, expect that some will be surprised to learn there’s virtually no difference among those that buy products with 
out-of-the-box integrations and those that build integrations on their own. Just under half (~49%) of organizations using each of 
these approaches report strong integration levels.

**Figure 7: Effect of common integration approaches on level of security tech integration**
*   A bar chart showing the percentage of organizations with strong tech integration based on their integration strategy. The categories are:
    *   Nothing extra: 30.6%
    *   Out-of-box: 48.8%
    *   Build our own: 49.0%
    *   Preferred vendor: 68.8%
    *   Overall: 56.1%

## Cloudy, with a chance of integration
We’ve heard from many organizations wrestling with the decision whether to begin (or expand) their security tech integration efforts 
in the cloud or in on-prem environments. If that’s you, we have some data that might help that evaluation. The good news is that 
many survey respondents report good results in both on-premises and cloud environments. That said, it appears to be significantly 
easier to achieve strong tech integration in the cloud. 

**Figure 8: Effect of cloud vs. on-premises environments on level of security tech integration**
*   A bar chart showing the percentage of organizations with strong tech integration based on their IT environment. The categories are:
    *   On-prem IT: 47.1%
    *   Cloud IT: 72.0%

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
15

## Does integration aid automation?
Referring back to the start of this section, automation isn’t the most common motivation for tech integration. But 44% of organizations 
did identify it as an incentive. Motivations aside, is there evidence that well-integrated technologies actually do enable better 
automation of security processes? The evidence put forward in Figure 9 points to that indeed being the case.

**Figure 9: Effect of tech integration on extent of security process automation**
*   A stacked bar chart showing the percentage of organizations with different levels of security process automation based on their level of tech integration. The categories are:
    *   Weak integration:
        *   0 highly automated processes: 61.6%
        *   1 highly automated process: 24.6%
        *   2 highly automated processes: 9.7%
        *   3 highly automated processes: 4.1%
    *   Strong integration:
        *   0 highly automated processes: 21.8%
        *   1 highly automated process: 28.5%
        *   2 highly automated processes: 30.0%
        *   3 highly automated processes: 19.8%

The two horizontal bars in Figure 9 distinguish organizations based on their level of security tech integration (strong vs. weak). The 
color segments represent the number of major security processes (event monitoring, incident analysis, and incident response) 
supported by mature automation. The proportion of organizations with no automation is more than twice as high among those with 
weak integration. Conversely, those with well-integrated security technologies were almost seven times more likely to achieve 
high levels of automation for all three of these processes (4.1% vs. 28.5%). That sounds like a compelling motivation indeed!

## Which functions should be integrated?
Next, we asked respondents about their level of integration among technologies supporting the five core functions of the NIST 
Cybersecurity Framework (CSF). They answered on a scale ranging from highly fragmented (siloed technologies that work mostly in 
isolation) to highly integrated (coordinated technologies that work as a functional unit). Then we created a model to determine the 
effect on the overall security outcomes score for each organization.

The results in Figure 10 are fairly consistent across the five functions. Working to defragment and integrate any of the NIST CSF 
functional areas corresponds to an increase in security program success (+11% to ~15%). Thus, the answer to our titular question 
is “all of them.” But a highly integrated ‘Identify’ function boasts the biggest boost if you’re wondering where to start.

**Figure 10: Effect of integrating NIST CSF functions on overall security outcomes score**
*   A bar chart showing the percentage difference from the mean security outcomes score based on the level of integration of the NIST CSF functions. The categories are:
    *   Identify:
        *   Fragmented: -7.3%
        *   Highly integrated: 7.3%
    *   Protect:
        *   Fragmented: -5.5%
        *   Highly integrated: 5.6%
    *   Detect:
        *   Fragmented: -5.4%
        *   Highly integrated: 6.7%
    *   Respond:
        *   Fragmented: -5.6%
        *   Highly integrated: 6.8%
    *   Recover:
        *   Fragmented: -5.8%
        *   Highly integrated: 7.1%
    *   Average score: 501

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
16

We can’t help but see a connection between this fact and what we learned in the previous section about monitoring, auditing, and 
collaboration being the strongest drivers for integrating technology. Together, they seem to advocate for the foundational importance 
of good visibility across the enterprise. It certainly makes sense that a fragmented approach to “developing an organizational 
understanding to manage cybersecurity risk to systems, people, assets, data, and capabilities” (CSF language) won’t end well. You’ll 
see this theme further reinforced as we roll into the Threat Detection and Incident Response section.

## On integration, identification, and information
Beyond the chart we just discussed, data throughout this study consistently points to the crucial relationship between integration, 
identification, and information. If you can’t identify an asset or threat, you won’t know it’s there, and therefore won’t be concerned 
enough to establish an informed defense until it’s too late. 

Figure 11 illustrates this concept well. We compared each organization’s reported level of integration within the NIST CSF ‘Identify’ 
function to their ability to accurately detect threats in a timely manner. Organizations with highly integrated systems for identifying 
critical assets and risks boasted much stronger (+41%) threat detection capabilities. So, in a real sense, fighting fragmentation and 
fighting foes go hand-in-hand!

**Figure 11: Effect of integrating the NIST CSF Identify function on threat detection capabilities**
*   A bar chart showing the percentage of organizations with strong threat detection based on their level of integration of the NIST CSF 'Identify' function. The categories are:
    *   Fragmented: 33.1%
    *   Highly integrated: 74.1%
    *   Overall: 53.4%

+4
1
% stronger threat 
detection capabilities
Organizations with highly integrated systems 
for identifying critical assets and risks had

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
17
Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
18

> “Automation allows our engineers to react 
to emerging threats in a timely manner. 
We can now focus on getting the security 
concepts right instead of continually updating 
the rules and monitoring the network 24/7. 
Cisco wades into the weeds and extracts the 
information we need so we can do a better 
job securing and maintaining our infrastructure. 
It has given us the perfect combination of 
machine and human intelligence.” 
>
> Steve Erzberger, CTO, Frankfurter Bankgesellschaft (Schweiz) AG

[Read more](link-to-read-more)

# Developing Threat Detection and Incident Response Capabilities
This section covers two separate security practice areas that both made the Fab Five in their own 
right. But because threat detection and incident response (IR) often share people, processes, and 
technologies under the banner of security operations (SecOps), we asked a set of common questions 
between them. Thus, it makes sense to analyze them within the same section for this study.

Nearly all (about 92%) of organizations 
with strong people, process, and 
technology achieve advanced threat 
detection and response capabilities.

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
19

## Prioritize people, process, or technology?
Speaking of people, processes, and technology (aka the p-p-t triad), let’s start our investigation there. Security functions are often 
described as a combination of all three elements, particularly in the domain of threat detection and incident response. But is any part 
of this security trinity more critical than the others? You know where this is going; let’s jump into the analysis.

Starting from the bottom of Figure 12, we see that only about a quarter of programs lacking strength in all facets of the p-p-t triad 
express confidence in their SecOps. Gaining strength in any one area — people, process, or technology — boosts that percentage 
up to roughly 60% to 64%, depending on which one. Strong people appear to grant a slight edge, but the overlapping confidence 
intervals caution against making too much of that fact. The important takeaway is that any of these offer a good starting point for 
building better detection and response capabilities.

**Figure 12: Effect of strong people, process, and technology on threat detection and incident response capabilities**
*   A bar chart showing the percentage of organizations with strong detection and response capabilities based on their program strengths. The categories are:
    *   None: 26.0%
    *   Tech: 59.5%
    *   Process: 61.5%
    *   People: 64.0%
    *   People/Tech: 79.8%
    *   People/Process: 80.7%
    *   Process/Tech: 84.7%
    *   People/Process/Tech: 91.8%
    *   Overall: 67.2%

Continuing up Figure 12, doing two 
things well moves SecOps programs 
solidly above the average and improves 
capabilities by about 15% to 20% over 
those that just do one thing well. Once 
again, it doesn’t really matter which 
people, process, technology pairing 
you choose. You just need strength in 
any two. It’s nice to know that there’s 
some freedom of choice in tailoring your 
organization’s SecOps roadmap, isn’t it?

And that brings us to elite programs 
in Figure 12 that manage to attain the 
SecOps trifecta. Nearly all (about 92%) 
of organizations with strong people, 
process, and technology achieve 
advanced threat detection and response 
capabilities. That’s a 3.5X performance 
increase compared to SecOps programs 
that don’t get any of those right! So, 
start wherever you can make the most 
headway, but don’t stop until you reach 
the p-p-t pinnacle.

3.5X
Organizations with 

strong people, processes, 
and technology see a
performance increase for threat 
detection and response over those 
lacking strength in all of these areas

Security Outcomes Study, Volume 2
Maximizing the Top Five Security Practices
20

## Do zero trust and SASE