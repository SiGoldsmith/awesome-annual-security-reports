# Insights and Trends in Software Security Testing from Black Duck Global State of DevSecOps 2024

## Table of Contents
- [Executive Summary](#executive-summary)
- [About Black Duck](#about-black-duck)
- [Findings Overview](#findings-overview)
- [A Deep Dive into the State of DevSecOps in 2024](#a-deep-dive-into-the-state-of-devsecops-in-2024)
- [The AI revolution in security testing](#the-ai-revolution-in-security-testing)
- [Interpreting and acting on security test results](#interpreting-and-acting-on-security-test-results)
- [From interpretation to action](#from-interpretation-to-action)
- [Conclusion](#conclusion)
- [Appendix](#appendix)
- [Questions](#questions)

## Executive Summary
It is a time of radical change in software development, with organizations in every industry recognizing the need for robust, efficient security processes that can keep pace with new development practices, such as AI-assisted coding.

The findings in the “Global State of DevSecOps 2024” report are based on a comprehensive survey that Black Duck® commissioned from Censuswide, an international market research consultancy. More than 1,000 software developers, application security (AppSec) professionals, CISOs, and DevOps engineers across multiple countries and industries were included in the survey.

This report provides critical insights into the current state of DevSecOps practices and AppSec testing. It delivers a comprehensive analysis of trends, challenges, and opportunities, and it offers actionable insights for organizations seeking to enhance their DevSecOps practices.

## About Black Duck
Formerly the Synopsys Software Integrity Group, Black Duck offers the most comprehensive, powerful, and trusted portfolio of AppSec solutions in the industry. We have an unmatched track record of helping organizations secure their software quickly, integrate security efficiently in their development environments, and safely innovate with new technologies.

## Findings Overview
### AI-assisted development soars but securing AI-generated code lags far behind
One of the most striking discoveries in this report is that the AI revolution is already over—and AI won, at least when it comes to integrating AI into software development processes. The adoption of AI in software development has gone beyond a tipping point, with over 90% of the respondents to our survey using AI assistance in some capacity.

### Parallels between securing AI-generated code and securing open source
The rapid adoption of AI-assisted coding by software development teams shares several similarities with the historic rise of open source software use. Both movements disrupted traditional software development practices. Open source challenged proprietary software models, and AI-assisted coding is transforming how code is written and reviewed.

But just as with open source use, bringing AI-assisted coding tools into software development presents unique intellectual property (IP), licensing, and security challenges that need careful management by development teams. For example, both unmanaged open source and AI-generated code can create ambiguity about IP ownership and licensing—especially when the AI model uses datasets that might include open source or other third-party code without attribution.

AI-assisted coding tools also have the potential to introduce security vulnerabilities into codebases. One researcher flatly concludes that “autogenerated code cannot be blindly trusted, and still requires a security review to avoid introducing software vulnerabilities.”

There are clear challenges in managing and securing AI-generated code. Our survey found that organizations are at different stages of implementing policies and controls around AI tool usage, reflecting the nascent nature of this trend.

Although 85% of respondents to our survey say they have some measures in place to address the challenges posed by AI-generated code, only 24% are “very confident” in their policies and processes for testing such code. A total 67% of respondents feel only “moderately confident” (41%), “slightly confident” (20%), or “not at all confident” (6%).

This lack of confidence may reflect the fact that that 21% of respondents acknowledge that their development teams are bypassing corporate policies and using unsanctioned—and, one would assume, unsupervised—AI tools. Again, unmanaged AI use parallels the early days of unmanaged open source use, when few executives were aware that their development teams were incorporating open source libraries into proprietary code, let alone the extent of that use.

![Breakdown of confidence levels in policies and processes for testing AI-generated code: 24% Very Confident, 20% Slightly Confident, 41% Moderately Confident, 6% Not at All Confident]

### An increased focus on software security testing
Test coverage is substantial but not universal, with 57% of respondents testing between 41% to 80% of their projects, branches, and repositories, suggesting opportunities for expanding security test coverage.

Our findings show that organizations are prioritizing security testing based on the sensitivity of information handled (37% of respondents), while also emphasizing industry best practices (36%) and increasing use of automated security testing (35%).

Configuration of security tests is becoming more centralized, with 55% of respondents using centralized interfaces for test configuration. And although their execution is becoming more automated, the persistence of nonautomated activities documented in this report indicates substantial room for improvement. A significant percentage of respondents still uses manual processes in their application security testing and remediation workflows. The exact amount varies depending on which manual process we look at, but it ranges from about 15% to 43% of respondents.

### Too much noise, too many tools
A slight majority of respondents find security test results at least “somewhat easy” (52%) to understand and act upon, while another 20% deem their results “extremely easy” to understand. However, this perception varies across roles, industries, and geographies.

The findings also reveal a critical challenge with “noise” in security testing results; that is, output that is considered irrelevant or not worth acting upon. Noise is often caused by a high number of false positives or a large volume of duplicative true positives in results. Sixty percent of respondents reported that they consider over 20% of their results as noise, impacting efficiency and decision-making processes.

Despite a broader trend of integrating security into development processes, 61% of respondents report that security testing moderately or severely slows down development. The tension between security and development speed remains a critical challenge for every industry.

The fact that 82% of organizations use between 6 and 20 security testing tools is certainly a factor, with a broad proliferation of tools contributing to the high levels of noise reported by respondents. Multiple tools may detect the same issues, leading to duplicative results. Or different tools may provide conflicting results for the same code or application. Each tool may generate its own false positives, which compounds as more tools are used.

With so many tools in use, organizations are struggling to effectively integrate and correlate results across platforms and pipelines, leading to difficulty distinguishing between genuine issues and false positives, as well as challenges in prioritizing issues across different tools’ outputs.

### Looking ahead
Several key trends are shaping the path of DevSecOps.
- Increased automation of security testing and remediation processes
- A need for policies concerning the use of AI-assisted development tools
- Enhanced focus on reducing noise in security test results to improve efficiency
- The evolution of cross-functional collaboration in security decision-making

Organizations have significant opportunities to improve their DevSecOps practices by leveraging automation, enhancing the clarity of security test results, developing robust policies for AI-assisted development, and fostering better cross-functional collaboration.

As the landscape continues to evolve, organizations must stay agile, adapting their AppSec processes to meet emerging challenges. The most successful will be those that can effectively balance rigorous security practices with the speed and innovation demands of modern software development.

## A Deep Dive into the State of DevSecOps in 2024
Our survey of over 1,000 security professionals reveals a state of flux, with organizations striving to balance security measures with the demands of rapid development cycles. This section delves into the current state of AppSec testing and highlights key trends, challenges, and opportunities that define the testing landscape in 2024.

### Three priorities are driving security testing
Our results reveal that respondents to our survey have a clear set of priorities for effective security testing. Protecting sensitive information is a key mandate for security teams. Development teams value efficiency through automation and closed feedback loops, and implementing best practices for resilient pipelines is fundamental to operations teams.

#### Protecting sensitive information
The foremost consideration, cited by 37% of respondents, is protecting the sensitive information accessed or transmitted by the application. Taking a risk-based approach as these organizations are doing reflects a mature understanding of the impact potential breaches can have across different parts of an application ecosystem.

In a recent analysis of 1,300 customer applications, Black Duck found sensitive data exposure issues affecting 86% of those customers, accounting for over 30,000 vulnerabilities, including 4,800 critical-risk instances. Sensitive data exposure is one of the most common and serious security issues across industries. To address these vulnerabilities, organizations need to implement strong encryption practices, use up-to-date security protocols, and ensure that sensitive data is properly protected both when it’s being transmitted and when it’s stored.

Our data shows that organizations in sectors such as Application/ Software, Banking/Finance, Healthcare, and Government are particularly attuned to this priority, given the highly sensitive nature of the data they handle.

#### Adhering to best practices
Thirty-six percent of organizations rely on the best practices recommended by third-party organizations like OWASP. Adherence to established guidelines ensures a baseline of security across diverse development environments. However, it also raises questions about the adaptability of these standards in the face of rapidly evolving threats.

> Industry standards may have difficulty adapting in the face of rapidly evolving threats. For example, OWASP standards have yet to address the unique security challenges posed by AI-generated code.

#### Automating and ensuring ease of test configuration
The emphasis on automation and ease of test configuration, prioritized by 35% of respondents, underscores the growing integration of security into DevOps processes. This move toward DevSecOps reflects the recognition that security must be woven into the fabric of the development life cycle rather than treating it as an afterthought.

### Trending toward centralization
The top responses to the survey’s Question 2 reveal a clear trend toward centralization in tool configuration for efficiency and consistency. Thirty percent of respondents reported using a vendor’s interface to configure tests from that vendor, while 26% reported using a centralized interface for all tests, regardless of vendor.

Centralizing security tools allows for a unified management interface, which simplifies the monitoring and configuration of security measures. This reduces the complexity associated with managing multiple disparate systems, facilitates integration at each stage of the pipeline, and ensures that security policies are consistently applied across the organization. With a centralized system, security efforts can be more easily coordinated, reducing the likelihood of gaps or overlaps in security coverage. A centralized, holistic approach enhances the ability to detect and respond to threats across the entire IT infrastructure.

Centralized management also allows better visibility into an application’s security profile, enabling more effective identification and mitigation of vulnerabilities. Further, it facilitates the collection and analysis of security data, which is crucial for proactive threat detection and response.

Overall, centralization and vendor consolidation in security testing can significantly enhance an organization’s ability to protect its digital assets by simplifying management, improving coordination, and potentially reducing costs.

### A struggle to attain full security coverage
Despite the emphasis on comprehensive security, many organizations struggle to achieve full coverage, as the responses to Questions 3 and 4 demonstrate. Nearly 30% of respondents still add new projects, branches, or repositories to their application security testing queue manually. Six percent use mostly manual processes with some automation. In other words, about 35% of organizations are still heavily reliant on manual intervention in their security testing queue management.

While there are varying perceptions of the extent to which security testing impacts development workflows, survey results show a clear correlation between the perceived impact on testing and manual processes. For example, 50% of those that say application security testing slows down the process also say that most projects are added to the test queue manually.

However, 38% of respondents report that they are taking full advantage of automated processes to include all projects in test queues, and another 22% report mostly using automated processes. This means that 60% of organizations are leveraging automation to a significant degree in their security testing workflows.

Thirty-seven percent of respondents include only 41% to 60% of their projects, branches, and repositories in their testing queue. Twenty-one percent achieve 61% to 80% coverage.

This coverage gap presents significant risk, potentially leaving critical parts of an organization’s application ecosystem untested. While counterintuitive, some respondents noted slightly higher-than-average coverage despite using manual processes to add projects to the test queue. This may simply be the level of coverage being perceived as higher due to the greater level of effort to test each project.

> About 35% of organizations are still heavily reliant on manual intervention in their security testing queue management.

### Who determines when security tests are run
The responses to Question 5 offer valuable insights into how organizations are structuring their application security testing decisions. This data paints a picture of organizations increasingly treating security as a shared responsibility, integrated into various stages of the software development life cycle.

The close percentages for security (44%) and development/ software engineering (42%) suggest a trend toward shared responsibility for security testing. This aligns well with DevSecOps principles, indicating that security is becoming more integrated into the development process.

At 37%, DevOps teams play a significant role in security testing decisions. This further supports the trend toward integrating security throughout the development life cycle. At 34%, QA teams are also heavily involved, suggesting that many organizations view security as an integral part of overall software quality.

The involvement of compliance (28%) and legal (19%) teams indicates that regulatory and legal requirements are significant factors in security testing decisions for many organizations.

Twenty-one percent of respondents indicate that cross-functional groups are involved in these decisions, showing a trend toward collaborative, multidisciplinary approaches to security. With only 1% selecting “None of the above,” it’s clear that the majority of organizations have specific teams or processes in place for determining security testing.

The distribution across teams suggests a relatively mature approach to security in many organizations, moving away from security as solely the responsibility of a dedicated security team. These results align with broader industry trends toward DevSecOps and “shift-everywhere” security practices, as described in the “Building Security in Maturity Model” report, where security is integrated earlier and more continuously in the development process.

### A tool proliferation challenge
One of the most striking findings from our survey is the sheer number of security testing tools in use, as shown by the responses to Question 6. Eighty-two percent of organizations use between 6 and 20 security testing tools.

A proliferation of tools, although intended to provide comprehensive coverage, introduces significant complexity in integration, results interpretation, and overall management. It correlates strongly with another key challenge—noise in security testing results.

### The noise factor
Question 9 uncovers a significant hurdle in effective security testing: the high level of noise in results. A total of 60% of respondents reported that between 21% and 60% of their security test results are noise. A high noise level can significantly impact the effectiveness of security efforts and lead to efficiency loss, as teams must spend time filtering out irrelevant findings. It can also lead to alert fatigue and genuine threats being overlooked, as well as resource misallocation due to organizations directing too much of their security efforts toward noncritical issues.

### Role-based differences
There is a perception among security personnel of a high percentage of noise within security test results. This is likely because security teams are commonly tasked with managing security tests, as they sit toward the top of the review funnel. These teams present dev/engineering teams with cleansed and prioritized results, which in turn results in those teams skewing toward lower perceived noise.

Likewise, 17% of dev/engineering personnel feel they don’t have enough visibility into security tests to identify noise in results. This is in stark contrast to CISOs, CTOs/CPOs, and AppSec professionals; only 1% of respondents in those roles cite a lack of visibility when detecting noisy results. One core tenet of efficient DevSecOps is adequate visibility into software artifacts and associated risks across all teams. Inadequate visibility can slow down issue detection, prioritization, and remediation, and leave pipelines prone to breakdowns and software open to attack.

## The AI revolution in security testing
Over 90% of organizations are using AI tools in some capacity for software development. The distribution of responses to Question 14 illustrates a seemingly phased adoption curve. Twenty-seven percent of respondents note that all developers are permitted to use AI, generative, or transformational tools in their work, while 43% permit only certain developers or teams to use such tools, and 21% forbid their use alongside an awareness that such tools are, in fact, being used by their developers.

### Worldwide AI adoption
The regional responses to Question 14 demonstrate that AI adoption in software development is not only a phenomenon—it is a global phenomenon, with slight variations in results probably reflecting differences in technological infrastructure, regulatory environments, or cultural attitudes toward AI.

Similar numbers play out by industry sector, with over 90% adoption reported across the Technology, Cybersecurity, FinTech, Education, Banking/Financial, Healthcare, Media, Insurance, Transportation, and Utilities sectors. Even lagging sectors, such as Nonprofit, report at least 50% adoption. Perhaps unsurprisingly, the larger the organization, the more likely it has significantly adopted some facet of AI in its software development.

This trend is reshaping the security testing landscape and also introduces new challenges, particularly in securing AI-generated code and managing potential biases or vulnerabilities that AI systems might introduce, as the responses to Question 15 show.

### Most respondents not confident they’re securing AI-generated code
While the net confidence level of respondents to Question 15 may seem high at first blush, a deeper dive into the responses show that 41% of respondents are only moderately confident that they have the policies and automated testing in place to adequately vet AI-generated code, while 20% are only slightly confident and 6% are not at all confident—a total 67% of respondents altogether showing concern about managing and securing AI-generated code.

This distribution suggests that even though their development teams are adopting AI tools, many organizations are still in the process of putting policies and tools into place to manage the unique challenges posed by AI-generated code. Ensuring the reliability and security of that code remains a significant challenge. As one example, AI tools trained on public open source codebases could introduce potential IP, copyright, and license issues into the code they produce, particularly if that code is used in proprietary software.

![Figure 1. Developers’ AI usage (permitted or not) correlated against moderate to high confidence in security controls]

In Figure 1, starting from the left, less than 5% of organizations forbid developers from using AI to write code or modify projects. Perhaps this group’s moderate and high confidence in their preparedness derives from their prohibition of the use of AI, or perhaps there are other access controls that preclude access to AI resources.

The second group, 27% of respondents, reports a strong awareness that AI is being used. Eighty-one percent have moderate or high confidence in their security preparedness (22% of overall responses). These respondents are readily leveraging AI tools and confident that they have the controls in place to mitigate consequent risks.

The third and fourth groups are in the midst of an AI evolution, with moderate to high confidence in their security preparedness and a seemingly phased approach to AI-enabled development.

![Figure 2. Developers’ AI usage (permitted or not) correlated against low to slight confidence in security controls]

### AI and code snippets
A common practice of developers is to use “snippets” (small extracts from larger pieces of code) in software, a problem now exacerbated by the use of AI coding assistants. Although code might include only a snippet of open source, users of the software must still comply with any license associated with the snippet.

Even one noncompliant license in software can result in legal reviews, freezes in merger and acquisition transactions, loss of intellectual property rights, time-consuming remediation efforts, and delays in getting a product to market.

Black Duck’s 2024 OSSRA report relates that over half—53%—of the applications examined contained open source with license conflicts, exposing those applications’ owners to potential IP ownership questions.

In Figure 2, we can see some dissonance between respondents’ use of AI-generated code and AI-assisted development, and the steps they’re taking to safeguard their intellectual property and mitigate security risks.

Starting from the left, the less than 5% that forbids the use of AI tools altogether exhibits slight or nonexistent confidence in security preparedness, with nearly 42% of this group claiming a lack of priority. Consequently, their choice to disallow AI-enabled development may stem from this lagging organizational approach to securing AI-generated code.

The rightmost group highlights a greater exposure to risk, where automated testing of AI-generated code is a notably lower priority despite an awareness of the use of AI-assisted development.

The group second from right illustrates a seemingly phased adoption of AI-enabled development and security controls, with limited permission being granted, perhaps based upon a slight confidence in preparedness.

Most concerning is the group second from left, which has some development teams that are using AI with permission, despite a clear lack of confidence in their preparations to mitigate risks.

## Interpreting and acting on security test results
The effectiveness of application security testing hinges not just on the execution of tests, but also on the ability to interpret results and take appropriate action. This section examines the current state of result interpretation and remediation based on our survey results, highlighting both progress and persistent challenges in the field.

### Role-based differences
Our analysis suggests that CISOs, CTOs/CPOs, and AppSec professionals generally reported higher levels of ease in understanding and acting upon security test results compared to other roles (Question 7). For example, 37% of CISOs, 23% of CTO/CPOs, and 21% of AppSec professionals found security test results “extremely easy” to understand and to act upon. In contrast, only 14% of DevOps and dev/engineering personnel found these tasks extremely easy. This may be due to senior-level personnel having more experience or better interpretative tools at their command than workers in the trenches. Unfortunately, those workers are usually the ones on the front line of security testing and the ones whose efforts are being hampered by the lack of clarity in testing results.

### Geographical differences
Notable variations were observed across countries. For example, 88% of respondents in China found testing results easy to understand, compared to 55% in the U.S. and 51% in Japan. These regional disparities suggest differences in tool adoption, security culture, or regulatory environments across countries.

### Different approaches to parsing and cleansing results
The process of parsing and cleansing security test results reveals a spectrum of approaches (Question 8). For example, 38% of respondents manually parse and cleanse results from all tools. Twenty-five percent report fully automated parsing and cleansing of results. Twenty-eight percent use a combination of automated and manual parsing and cleansing.

The prevalence of manual and hybrid approaches (66% combined) indicates a significant opportunity for increased automation and normalization in results processing. However, the challenge lies in balancing automation with the need for human expertise in interpreting complex security contexts.

![Figure 3. Impact of review method on understanding results and taking action]

As illustrated in Figure 3, it is possible to associate ease of interpretation and action with the method of parsing and cleansing data. The resulting insight reveals a clear benefit to establishing automated mechanisms for parsing and cleansing security test data, whether the benefit comes from accelerated review or more consistent elimination of noise before human consumption. Of those that manually parse and cleanse test results, 22% find those results somewhat or extremely difficult to understand and act upon. Of those that use automated means, only 10% find the same difficulty.

Conversely, 90% of those that use automated methods to parse and cleanse data find the results of security tests somewhat or extremely easy to understand and act upon, while only 77% report the same ease by doing so manually. Notably, when examining those with hybrid approaches to reviewing test results, we see a “worst of both worlds” experience, with 35% citing difficulty understanding and acting on results, and only 64% finding it easy to do so.

## From interpretation to action
### Constant security testing vs. development speed tension
Despite advancements in tools and processes, tension remains between thorough security testing and the need for development speed, as shown in the responses to Question 13. Eighty-six percent of respondents feel that security testing slows down development by some amount (ranging from slightly to severely). The plurality (43%) feels that testing moderately slows down development. While one-quarter of respondents feel that security testing slightly slows down development/delivery, and another 18% feel that it severely slows the development life cycle.

There may be more insight, though, in looking at how software projects are added to the security testing queue and whether that is an impediment to development and delivery pipelines. Of those that report security testing severely slows down their pipelines, 33% manage their test queues entirely manually, compared to 17% that manage pipelines entirely through automation.

These statistics underscore the ongoing challenge of integrating security seamlessly into fast-paced development cycles without becoming a bottleneck.

### Role-based differences
When examining potential differences in security testing’s impact on development and delivery pipelines, there are a few clear distinctions among roles, depicted in Figure 4.

AppSec teams, perhaps due to their proximity to the testing process or the pressures applied to them to accelerate review, show the greatest sentiment that tests moderately or severely impede pipelines (65%). Similarly, 58% of dev/engineering personnel share this sentiment. It’s important to note that visibility into security testing is a significant challenge for dev/engineering teams, making it likely more difficult for them to assess the impact of security tools. This can make a concerted DevSecOps initiative more difficult to implement, as critical contributors are unable to close feedback loops and optimize efforts appropriately.

![Figure 4. AppSec and dev/engineering perception of security testing’s impact on development/delivery]

Let’s now extend each role’s perception of pipeline impediment to include the method of managing the security testing queue. We can validate that each role benefits from automating security testing. When manually managing testing queues, 29% of dev/engineering personnel and 44% of security personnel feel severe impact on development and delivery timelines. When managing testing queues through automation, only 16% of dev/engineering personnel and 19% of security personnel feel a severe impact to development speed.

This illustrates a great benefit to development and delivery pipelines, yet also defines a consistent perception among dev/engineering teams that security testing tends to negatively impact their workflows. Ultimately, dev/engineering teams report only a 13% reduction in perceived slowdown, whereas security teams report a 25% reduction.

### How remediation is accomplished
A major goal of security testing is to drive remediation efforts. Our survey reveals several key aspects of the remediation process among respondents.

The responses to Questions 10 and 11 indicate that organizations are actively implementing automated security measures throughout the development life cycle, with a focus on communication, prevention, and integration with existing workflows. However, there’s still significant room for wider adoption of these practices.

### Prioritizing issues for remediation
Question 10 shows that nearly half the surveyed organizations are using automated systems to prioritize security issues, indicating a significant adoption of advanced risk management practices. But a substantial portion (43%) still rely on manual prioritizations. The close split between automated and manual prioritization suggests that the arena of software security testing is in a transition phase, with many organizations likely using a hybrid approach.

### What happens when security issues are discovered
The responses to Question 11 reveal that organizations are employing a variety of automated actions to address security issues, indicating a mature, layered approach to security.

The top actions involve alerting various stakeholders (38% for upstream contributors, 32% for downstream stakeholders), emphasizing the importance of communication in addressing security issues at a pace required by DevOps and CI/CD methodologies. High percentages for assignment via issue management tools (36%) reveal a focus on the DevSecOps requirement for closed feedback loops between security and development teams to accelerate remediation. Significant percentages for actions such as preventing code check-ins (32%), blocking promotion downstream (28%), and breaking builds (24%) demonstrate a shift toward using automated, preventive security measures to preclude risks and avoid realizing exploitable conditions in production environments.

However, while adoption of these automated actions is significant, there’s still room for growth, as no single action is implemented by more than 38% of organizations.

> Organizations are actively implementing automated security measures throughout the development life cycle, with a focus on communication, prevention, and integration with existing workflows. However, there’s still significant room for wider adoption of these practices.

### How developers are informed of issues
In the responses to Question 12, the top five methods of assigning remediation issues are all automated, indicating a strong trend toward automating the notification process. This aligns with broader DevSecOps principles of integrating security seamlessly into development workflows.

The prevalence of alerts within development tools (36%) and pipeline tools (35%) indicates an attempt to help developers fix issues more quickly. There is a high percentage of responses citing alerts within issue management tools (39%) and security tools (40%), which indicates multiple locations to access necessary risk information. This creates unnecessary deviations from development workflows. While not as common as automated methods, manual assignment of issues is still used by a significant portion (32%) of organizations.

> The top five methods of assigning remediation issues are all automated, indicating a strong trend toward automating the notification process. This aligns with broader DevSecOps principles of integrating security seamlessly into development workflows.

## Conclusion
As we conclude this examination of the current state and future trajectory of application security, it’s clear that DevSecOps is at a critical juncture. Our findings reveal both progress and problems in current DevSecOps practices.

Over 60% of respondents report that security testing moderately or severely slows down development, highlighting the ongoing challenge of integrating robust security practices without impeding agility. Over 80% of organizations use between 6 and 20 security testing tools, indicating a complex testing environment that can lead to integration challenges, noise, and alert fatigue. In fact, 60% of respondents report that anywhere from 21% to 60% of their security test results are noise, underscoring the need for more-effective filtering and prioritization mechanisms.

While 49% of organizations now use automated prioritization for security issues, reflecting a growing trend toward leveraging technology to streamline security processes, a significant number of respondents are still using manual processes in various aspects of their application security testing and remediation workflows.

With over 90% of organizations using AI tools in some capacity for software development, we’re witnessing a transformative shift in how applications are built and secured. This adoption brings both new capabilities and new security considerations. While adoption is high, only 24% of respondents are very confident in their policies, management, and testing for AI-generated code, indicating an area in dire need of automated processes.

The truth of the matter is that, while AI-assisted coding may be accelerating development, security processes—which are already struggling to keep up—are going to fall further behind without automation. Take the time now to critically evaluate your organization’s approach to software security testing.

> Over 60% of respondents report that security testing moderately or severely slows down development
> 49% of organizations now use automated prioritization for security issues
> Over 90% of organizations are using AI tools in some capacity for software development

Scrutinize your tool stack. Are you drowning in a sea of disparate solutions, or leveraging an integrated, streamlined suite of security tools?
- Evaluate your tools and processes. Aim for consolidation and results integration.
- Reduce tool proliferation and complexity where possible by choosing a primary vendor with the experience and knowledge to consolidate disparate tools into a comprehensive testing whole.
- Explore implementing an application security posture management (ASPM) solution to integrate tools, automate workflows, and normalize and prioritize results. Invest in tools and processes that consolidate security test results and make them more actionable and easier to understand across all roles in the organization.

Evaluate your automation levels. Our survey indicates that manual processes still dominate in many organizations. Identify where automation can be leveraged to boost speed, efficiency, and consistency.
- Explore integrating automated security checks into your CI/CD pipeline.
- Consider implementing infrastructure-as-code (IaC) with built-in security policies.
- Provide developers with IDE plugins for real-time security feedback and prioritized remediation guidance to help them fix faster and cultivate their security capabilities.

Establish AI governance today. Establish clear policies and procedures for the use of AI in software development. Invest in tools and processes designed to vet and secure AI-generated code.
- Static application security testing (SAST) is highly effective at identifying coding flaws early in the development process. This is crucial for vetting AI-generated code, which can inherit insecure coding flaws from its training data.
- Similarly, examining AI-created code with a software composition analysis (SCA) tool can help developers identify and secure outdated or insecure third-party components, as well as open source libraries with licenses that may potentially conflict with an organization’s business goals for its software.
- Dynamic application security testing (DAST) detects vulnerabilities at runtime and verifies issues’ exploitability. DAST scans are a critical component of application security testing, and the rise in AI-generated code only further highlights its importance. AI coding tools are trained using publicly accessible code repositories, for better or for worse. They are great for generating code quickly, but do not apply the same contextual reasoning a developer would to determine the best way to write code for a specific application. While teams can provide this context to AI tools in the form of prompt engineering, there are still limitations. Ensuring that the application is performing its desired function, and doing so securely, relies on application security testing. Doing so at the speed of AI-enabled development requires that it is tightly integrated into pipelines to allow for the detection of vulnerabilities in the context of the application in its running state.
- Ideally, all three security testing tools—SAST, SCA, and DAST—will run atop a centralized platform or be managed through an ASPM solution. You may also yield greater efficiency and scalability with proper integration and coordination with other AppSec testing tools, developer tools, and issue-trackers you are using.
- Protect sensitive data used to train AI models by ensuring that only authorized personnel have access. Encrypt data both at rest and in transit to prevent unauthorized access. Enforce the principle of least privilege to grant AI systems the minimum access necessary to perform their functions.

> Successful organizations will be those that view the challenges outlined in this report not as obstacles, but as opportunities for transformation and improvement. They’ll be the ones not just willing to adapt to the changing landscape of DevSecOps but determined to shape it. The future of DevSecOps is not predetermined—it’s waiting to be defined.

> What role will you play in the future of DevSecOps?

## Appendix
### Survey Respondents
#### Industries of Survey Respondents
![Industries of Survey Respondents: Technology 18%, Cybersecurity 7%, Application/Software Development 1%, Manufacturing 0.5%, FinTech 0.5%, Education 4%, Banking/Financial 4%, Telecommunications/ISP 2%, Healthcare 2%, Retail 2%, Media 6%, Government 3%, Insurance 3%, Transportation 6%, Nonprofit/Association 20%, Utilities 11%, Other 10%]

#### Job Roles of Survey Respondents
![Job Roles of Survey Respondents: CISO 16%, CTO/CPO 17%, InfoSec 14%, AppSec 11%, Dev/engineering 22%, DevOps 13%, Cloud ops 4%, QA/testing 2%, None of the above 1%]

#### Survey Respondent Country
![Survey Respondent Country: U.K. 12%, U.S. 13%, France 13%, Germany 13%, Finland 12%, China 12%, Singapore 12%, Japan 13%]

#### Organization Headcount
![Organization Headcount: Fewer than 100 4%, 100–500 11%, 501–1,000 13%, 1,001–2,000 16%, 2,001–5,000 17%, 5,001–10,000 18%, 10,001–15,000 10%, 15,001–50,000 7%, 50,001–100,000 14%]

## Questions
### Q1.
Which of the following criteria does your organization consider when determining which application security tests to run and when they are run?
- Sensitivity of information accessed/transmitted by the application 36.77%
- General best practices recommended by third-party organizations (e.g., OWASP) 35.88%
- Ease-of-configuration or automation of the security tests 35.38%
- Industry requirements or regulatory compliance 34.99%
- The application’s production environment 33.99%
- Attestation of security processes to stakeholders (e.g., customers, partners, investors) 33.70%
- Business criticality of the application 32.80%
- Release frequency or shipping deadline of the application 30.82%
- Recent publication of new vulnerabilities or zero-days 29.34%
- None of the above 2.78%

### Q2.