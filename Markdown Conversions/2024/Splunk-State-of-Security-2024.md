# State of Security 2024
## The Race to Harness AI

As a security professional and leader for over twenty years, I’ve witnessed the industry evolve many times over. But this time is different. Cybersecurity is rushing into a new frontier — one rife with opportunity and risk with the rise of generative AI. In Splunk’s 2024 State of Security Report, we found that many CISOs and practitioners are blazing this trail without looking back. But they’re also not sure what’s ahead, given new compliance regulations and their impact on CISO accountability.

In today’s cyber environment, we expect security professionals to explore how generative AI can empower their resilience journey — and with a staggering 93% of respondents claiming adoption, many already see it as a critical point of innovation. They’re using generative AI to build better cyber defenses, execute more informed decisions, and fill critical skills gaps. At the same time, at least one-third of respondents have no generative AI policies. And their biggest reported fear? AI-powered attacks.

Meanwhile, more punitive incident reporting rules by the U.S. Securities and Exchange Commission (SEC) and the E.U.’s NIS2 are holding the CISO community to greater accountability. But we believe security professionals will also discover new opportunities to reshape their roles and teams. For CISOs, that means asserting priorities in the boardroom, and for security practitioners, it calls for tighter collaboration with ITOps, engineering, and cloud teams to expand visibility, minimize response times, and take resilience to new levels.

While security professionals continue to forge this new path, at Splunk we are excited about the potential of generative AI for defenders and encouraged by how quickly security priorities are becoming business priorities.

Jason Lee
Chief Information Security Officer, Splunk

---

The state of security in 2024 is a bit of a contradiction. Despite the obstacles in security professionals’ paths — stringent compliance requirements, escalating geopolitical tensions, and a more sophisticated threat landscape — the industry is making progress.

Many organizations report that cybersecurity is becoming easier to manage compared to previous years. Organizations collaborate more and detect threats faster, and most have the authority and resources to solve the issues they face.

Complete victory remains elusive, however, as defenders attempt to outrun adversaries in the race to harness generative AI. Security teams are understandably concerned that generative AI will intensify the impact of the same attacks they’ve skillfully thwarted for years.

We think defenders are up to the task. The full impact of generative AI on cybersecurity may be unknown, but one thing we do know: The race is on.

## Innovation in flux

### Contents

*   [Innovation in flux](#innovation-in-flux)
*   [Entering the AI gold rush](#entering-the-ai-gold-rush)
*   [The building blocks of leading organizations](#the-building-blocks-of-leading-organizations)
*   [Sizing up the threat landscape](#sizing-up-the-threat-landscape)
*   [The mounting pressure of compliance](#the-mounting-pressure-of-compliance)
*   [Forging ahead](#forging-ahead)
*   [Industry highlights](#industry-highlights)
*   [Country highlights](#country-highlights)

---

Cybersecurity is trending easier over time

Being a defender means you rarely see the fruits of your labor. It’s only natural to wonder: is any of this working? When it comes to keeping up with cybersecurity requirements, respondents were almost evenly split: 41% say it has become easier, while 46% find it more difficult.

However, the macro trends paint a hopeful picture. Since Splunk’s State of Security 2022, managing cybersecurity is trending easier. This perception may be surprising given increasing environmental complexity and attack sophistication. But it’s likely easier for organizations with well-established security controls and processes to stay ahead of threat actors relying on tried-and-true attack strategies.

Collaboration may be one reason cybersecurity is getting easier: 87% of respondents say they are working more closely with other teams compared to a year ago. Three-quarters (75%) of respondents are joining forces more with IT operations this year. In addition, 54% are collaborating more with software engineering — and when security starts early in the design and coding phases, addressing vulnerabilities becomes more manageable.

Organizations are also detecting threats faster. Fifty-five percent of respondents estimate their mean time to detect (MTTD) distruption-causing incidents as 14 days or less. This marks a significant improvement from last year, when only 28% of respondents estimated detection within the same timeframe. However, this is still too much time for attackers to access systems.

*Image Description: A stacked bar chart showing the trend of keeping up with cybersecurity requirements over the past two years. The chart compares the percentage of respondents who find it "More difficult", "No more difficult", and "Easier" across the years 2022, 2023, and 2024.*

But the battle isn’t over

Among those who say cybersecurity is getting more difficult, 38% cite threat landscape sophistication as the reason why. Geopolitical tensions and cyber warfare are on the rise. IoT, AI, and multicloud environments are increasing data volumes exponentially. And as a result, organizations still trying to implement basic cybersecurity controls will struggle to secure additional assets and endpoints. They’ll also have a harder time protecting against simple human errors, like misconfigurations, which rank as this year’s top threat vector.

Tighter compliance requirements also raise the stakes, particularly for security executives who are now personally on the hook for their organizations’ violations. Twenty-eight percent agree that regulatory compliance is making the job harder. And new government mandates will only ratchet up the pressure.

Similar to previous years, 27% of security teams struggle to address emergencies and dedicate adequate time to improve cybersecurity, indicating a lack of long-term strategy and investment. A barrage of security alerts also makes it difficult to keep up — 26% agree the volume is troublesome.

AI rises above the clouds

One of the most notable findings in this year’s survey is that AI hype is on par with reality. Nearly half (44%) of respondents cite AI as among their three main initiatives in 2024, surpassing cloud security.

While security teams recognize the many benefits of AI, so do threat actors that are unencumbered by laws and policies. When asked whether AI will tip the scales in favor of defenders or adversaries, respondents are almost evenly divided: 45% predict adversaries will benefit most, while 43% say defenders will come out on top.

The meteoric rise of generative AI sparks the imagination of what could be, but it also raises serious questions about what will be. What will it mean for the SOC? Will organizations introduce policies to encourage safe and effective usage? How will they enforce those policies without hampering innovation? The answers are starting to take shape.

*Image Description: A bar chart showing the top security initiatives of 2024, with AI at 44%, Cloud security at 35%, and Security analytics at 20%.*

## Entering the AI gold rush

During the California Gold Rush, hundreds of thousands of prospectors with dreams of striking it rich migrated west. Similarly, today’s generative AI boom involves chasing opportunity at breakneck speed into an unknown frontier, where the possibilities feel endless and the risks perilous. Everybody wants to strike the mother lode and enjoy first-mover advantage. It’s possible — it just takes a little digging.

Generative AI adoption outpaces policy

*   adoption across the business: 93%
*   adoption within security teams: 91%
*   lack a complete generative AI policy: 34%

The promise and possibility of generative AI

Generative AI has gone mainstream, and organizations are actively implementing it to transform their businesses. From serving up personalized customer recommendations in e-commerce to mapping the human brain to imitating the brushstrokes of Rembrandt, generative AI boasts an assortment of use cases in nearly every industry.

These aren’t mere speculations. Ninety-three percent of respondents report that line-of-business end users rely on public generative AI tools to help them do their jobs. This creates more work for security teams who protect the business from generative AI-related vulnerabilities such as data leakage.

Optimism about generative AI is powerful enough to sway even the most skeptical security professionals. Adoption is nearly as high among security teams as the overall business, with 91% of respondents using public generative AI. What’s more, they’re rooting for generative AI’s success, with 46% declaring that generative AI will be “game-changing” for their security teams.

The race to harness generative AI is so intense that 50% of respondents say their organization is in the midst of developing a formal plan for using generative AI for cybersecurity, but the plan isn’t complete or agreed upon.

Security and innovation can go hand in hand if done correctly. At the same time, we wonder if pressure from the business or board — or just good ol’ fear of missing out — is driving generative AI adoption among security teams.

> Just two years ago, it would’ve been almost preposterous to ask organizations how many end users are using public generative AI tools — but today, generative AI in the business is table stakes.
>
> — Kirsty Paine, Field CTO and Strategic Advisor for EMEA, Splunk

Generative AI policy is uncharted territory

“Move fast and break things” might sound counterintuitive to most security practitioners, but it could be the right philosophy as organizations seek innovation at speed. And while security teams rarely turn down a chance to write a policy, 34% of organizations do not have a generative AI policy in place, despite its high adoption rate.

“Companies that clamp down too tightly on the use of generative AI risk not only falling behind their competitors, but also leaving themselves open to the threat actors who won’t hesitate to use these tools,” says Shannon Davis, principal security strategist at Splunk SURGe.

If we learned anything from cloud or IoT adoption, a lack of process and planning could come back to haunt security teams. The push from the business to haphazardly follow these trends resulted in undesirable consequences, such as non-compliant clouds paid on personal credit cards, or unsecured IoT devices rife with software vulnerabilities. Security teams must balance the speed of innovation with thoughtful and sustainable processes.

Robust policies depend on understanding the implications of a technology, yet 65% of respondents admit they lack education around generative AI. Teaching the rest of the organization about generative AI shouldn’t be the sole burden of the cybersecurity team, however.

> “Organizations should form a cross-functional governance board to oversee the development and adoption of AI with a comprehensive framework for responsible AI,” says Hao Yang, VP of AI at Splunk.

The influence of generative AI is wide-reaching, so navigating it calls for a range of perspectives and specializations. Splunk’s AI committee, for example, spans multiple business units, including product and technology, legal, privacy, security, human resources, go-to-market, and marketing.

Of course, thoughtful security policies don’t necessarily translate to complete prevention, but they can go a long way to minimize data leakage and other new vulnerabilities.

The long arm of the law comes for generative AI

Like internal governance, the frontier of generative AI remains relatively untamed and unregulated by any enforceable laws — for now. However, AI compliance is starting to take shape.

For example, The European Union’s AI Act aims to introduce a common regulatory framework based on risk categories. In 2023, the European Parliament amended its initial proposal to include generative AI, which must comply with certain transparency requirements. These requirements include registering the foundation model in a database and developing and retaining technical documentation.

In the United States, the Biden Administration’s AI Bill of Rights suggests that users should be notified when they are communicating with an automated system, and allows to opt out and interact with a real person instead. These guidelines could foreshadow future government action.

This impending tsunami of government regulation may be why 45% of respondents name better alignment with compliance requirements as a top area for improvement, right behind data leakage. Getting ahead of this trend requires a renewed focus on internal compliance controls.

> Organizations should form a cross-functional governance board to oversee the development and adoption of AI with a comprehensive framework for responsible AI.
>
> — Hao Yang, Vice President of AI, Splunk

*Image Description: A pie chart showing the split opinions on whether Generative AI will benefit defenders or adversaries. 45% believe adversaries will benefit most, 43% believe defenders will benefit most, and a small 12% believe they will cancel each other out.*

What generative AI use cases may look like in practice

*   Identifying risks: Generative AI can enhance risk-based alerting by quickly aggregating diverse datasets to provide security analysts with alerts that are context-rich. Large language models (LLMs) help to deliver this information at a speed and efficiency far beyond human capability.
*   Threat intelligence analysis: LLMs can determine the indicators of compromise and MITRE ATT&CK techniques described in a threat intelligence report. This would save intelligence teams from a lot of drudgery and enable them to perform deeper analysis faster.
*   Threat detection and prioritization: Prioritizing and triaging alerts are tasks particularly susceptible to analyst misclassification, fatigue and human errors. Generative AI can parallel process multiple threats while improving accuracy.
*   Summarizing security data: Generative AI can summarize quickly, thoroughly and accurately to help security teams save time and keep up with news and information, like Biden’s Executive Order on Improving the Nation’s Cybersecurity.

*Image Description: A bar chart showing the top generative AI cybersecurity use cases. Risk identification and threat intelligence analysis are both at 39%, threat detection/prioritization at 35%, and summarizing security data at 34%.*

Generative AI as the security sidekick

Perceptions of generative AI are evolving fast. Just eight months ago, only 17% of respondents in our CISO report said generative AI would advantage defenders. Now, almost half (43%) feel the same way.

More and more vendors are incorporating generative AI into their products, demonstrating its use in security workflows, and defenders are starting to see the possibilities. While the potential for novel generative AI-fueled attacks and AI poisoning remains a possibility, they have yet to become commonplace.

Defenders seem optimistic and agree that generative AI is a good match for several cybersecurity use cases, naming threat intelligence analysis and risk identification as the top two applications.

Solving the cybersecurity skills shortage

Skilled professionals sit at the heart of any SOC, and many organizations are still coping with talent shortages. Generative AI could offer some breathing room to address this very real need.

Eighty-six percent of organizations believe generative AI will help them hire more entry-level cybersecurity talent, and 58% say it would help onboard entry-level talent faster. Ninety percent of respondents say that entry-level staff can lean on generative AI to help develop their skills in the SOC once they’re hired — which could include fundamental tasks such as writing a Python script or spinning up test environments.

Generative AI will also be a force multiplier for seasoned security professionals. Sixty-five percent believe it will make them more productive, enabling experienced practitioners to more easily synthesize news and information, and accelerate research and detection engineering.

And while the fear of AI replacing jobs isn’t entirely unfounded — about half (49%) say generative AI will eliminate some existing security roles — it’s more likely to help organizations train new talent and prevent employee burnout. It could also simply reshuffle the deck of cybersecurity talent as it introduces new roles like prompt engineering.

*Image Description: Text highlighting the benefits of Generative AI in closing skill gaps. 86% believe it can help organizations hire more entry-level talent, and 65% believe it will allow seasoned security pros to be more productive.*

Generative AI as the attacker’s ally

Security teams are also rightfully concerned that generative AI is yet another tool in the arsenals of adversaries. Forty-five percent of respondents believe generative AI will be a net win for cyber attackers, and 77% say it expands the attack surface to a concerning degree.

Same attacks, different day

What unique threats will generative AI unleash upon the world? Odds are that instead of an immediate windfall of new attacks, generative AI will amplify threats already confronting security teams.

Thirty-two percent of respondents are most concerned about attackers using generative AI to optimize existing attacks, such as crafting more realistic phishing emails or refining malicious scripts. Less skilled, opportunistic hackers will exploit generative AI to drive a significant uplift in social engineering attacks. And 28% of respondents worry that generative AI will also help adversaries increase the volume of existing attacks.

The enemy within

Not all AI threats originate from outside sources; 77% of respondents agree that more data leakage will accompany increased use of generative AI. However, only 49% are actively prioritizing data leakage prevention — possibly because there aren’t many solutions yet that control the flow of data in and out of generative AI tools.

Lack of education around generative AI only amplifies these concerns. When 65% of security executives admit they don’t fully understand generative AI, it’s fair to assume confusion is even higher among non-security roles. Without the proper education, end users are bound to make mistakes like putting sensitive company data into an LLM, which will place security teams in the crosshairs.

*Image Description: A bar chart showing the top uses of generative AI by threat actors. Making existing attacks more effective is at 32%, increasing the volume of existing attacks is at 28%, creating new types of attacks is at 23%, and reconnaissance is at 17%.*

> It’s like the question, ‘Would you rather fight a horse-sized duck or 100 duck-sized horses? It’s probably more manageable to focus on a single threat, but generative AI will create the less-appealing scenario, acting as a force multiplier for existing attacks.
>
> — Kirsty Paine, Field CTO and Strategic Advisor for EMEA, Splunk

*Image Description: Text highlighting that 93% of respondents say experiences with ML will influence their future approach to generative AI.*

Mapping the future of generative AI

Where will generative AI go from here? No one has a crystal ball, but security teams have been embracing traditional forms of AI like machine learning (ML) for some time, and 93% say these experiences will influence their future approach to generative AI.

Many organizations have gotten a taste of the increased productivity that ML tools provide, with 92% receiving substantial advantages already. The technology is not perfect, though, and needs special care: 73% say tools with traditional AI and ML capabilities can generate false positives, and 91% say they require tuning. Similarly, generative AI calls for oversight to spot and prevent hallucinations that can undermine its value.

Those pioneers who have already built a solid foundation with traditional AI and machine learning will likely find themselves on the fast track of their generative AI journeys.

## The building blocks of leading organizations

In the race to stay ahead of threats, some organizations follow a center of excellence model to build mature cybersecurity practices. In 2024, 47% of respondents identify their security programs as “extremely advanced.” We’re classifying this group as leaders and will be comparing their unique characteristics and survey responses with those of the cohort who labeled their programs as “developing.”

For starters, leaders are confident in their ability to keep up with the threat landscape. Forty-nine percent of leaders say managing cybersecurity requirements is getting easier, while only 29% of respondents with developing programs say the same. Leaders also outperform those with developing programs in several other aspects, painting a picture of what may be considered gold standard practices.

Resource and empower appropriately

Leading organizations aren’t born; they are made. Their winning approach reflects a deep connection to the board and business stakeholders, cross-departmental collaboration and steady investments. Leading security teams have the budget to be proactive — 67% are significantly increasing cybersecurity spending in the next one to two years, versus 28% of respondents with developing programs.

A close connection to the business pays off for leading organizations, too. An impressive 95% say they have the resources and authority to address challenges, which mirrors the finding in our CISO Report that 47% of CISOs now report to the CEO.

Collaborate and recognize resilience

Being connected to the business isn’t just about having the CEO’s ear, it requires partnering across the business. Leading organizations collaborate more with these tech departments:

| Collaboration with        | Leading organizations | Developing organizations |
| :------------------------ | :-------------------- | :----------------------- |
| Software engineering      | 56%                   | 46%                      |
| Engineering operations    | 51%                   | 31%                      |
| IT operations             | 76%                   | 67%                      |

Collaboration also extends to compliance. Forty-nine percent of leading organizations strongly agree that everyone on the security team makes compliance a part of their jobs, compared to just 27% of organizations with developing security programs.

Leading organizations recognize that there’s a lot on the line when it comes to digital resilience. They more strongly agree that greater digital resilience leads to more innovation (41%), less business disruption (39%), and avoiding compliance penalties (39%) — likely because they’re more closely connected to business outcomes.

> Without executive buy-in, achieving cybersecurity maturity is a losing battle.
>
> — Jason Lee, CISO, Splunk

Innovate more with generative AI

Leading organizations are also more likely to innovate with AI, with 48% declaring it as a top initiative, compared to 30% of their less mature peers. Generative AI adoption among their security teams is higher and more widespread, too — 75% of leaders say that most security team members were using generative AI, and only 23% of developing organizations say the same.

Generative AI usage among leading organizations appears to be less experimental and more methodical in contrast to developing organizations:

*   82% of leaders have established generative AI security policies, while only 46% of developing organizations have done so.
*   55% of leaders have a formal plan to use generative AI for cybersecurity use cases, while only 15% of developing organizations make this claim.

Detect and respond to incidents faster

Cyber maturity doesn’t translate to fewer cyberattacks. However, leading organizations detect and respond faster than their peers, which softens the blow of an attack and its consequences.

For incidents that caused disruption, leading organizations cite a mean time to detect (MTTD) of 21 days, while developing organizations, on average, spend over a month (34 days) detecting a threat within their networks. Leading organizations also spend far less time in recovery mode. Their average mean time to recover (MTTR) business-critical workloads is just over 44 hours, while developing organizations’ average recovery time is 5.7 days.

> The ability to reduce detection and response time speaks directly to the maturity of a security program. That’s why MTTR and MTTD are such crucial metrics for boards and executives. They want to see measurable success in the long term.
>
> — Mick Baccio, Global Security Advisor, Splunk

*Image Description: A comparison of key metrics between organizations with extremely advanced programs and organizations with developing programs. The metrics include cybersecurity spending increases, resource availability, collaboration with engineering and IT operations, presence of generative AI policies, generative AI usage by security teams, MTTD of disruption-causing incidents, and MTTR for business-critical workloads.*

## Sizing up the threat landscape

While security teams fight the good fight, threat actors will still find ways to slip past even the best defenses. The State of Security 2024 demonstrates that attackers aren’t slowing down, with data breaches and ransomware increasing 13% and 14% respectively since 2021.

In 2024, we’ve seen attackers use diverse tactics — for example, business email compromise capitalizing on human deception, to DDoS attacks relying on brute force. Despite these varied approaches, these threats share an objective: cause disruption.

Cybersecurity incidents still have far-reaching reputational, legal, and financial consequences, but organizations appear to be better at absorbing the blow — even while enduring more attacks overall. For example, only 44% of respondents say that remediating incidents required significant time and personnel this year, down 13% from last year. Also, fewer respondents lost productivity and suffered confidential data breaches this year, indicating that digital resilience initiatives are working.

*Image Description: A bar chart showing the most frequent incidents experienced in the past two years. The incidents listed are data breach, business email compromise, cyber extortion, identity management attack, DDoS attack, ransomware, regulatory violation, software supply chain attack, digital asset fraud, and system compromise.*

Cyber anxieties don’t always match realities

While million-dollar ransom payments, CISO indictments and zero-days make great headlines, they are uncommon. When cybersecurity professionals are asked about threats they find most concerning versus those they are actually experiencing, their fears are sometimes misplaced.

For example, though respondents say AI-powered attacks are their number one concern, they experience data breaches, business email compromise, system compromise, and identity-based attacks far more often.

The opposite is also true — the perceived threats pale in comparison to the actual attacks. Only 18% of respondents rank business email compromise (BEC) as their most concerning threat, even though it was number two on the list of most common incidents in 2024.

However, some fears line up to reality. Data breaches, for instance, are both a top concern and the attack experienced most often, with 52% reporting at least one data breach incident in the past two years.

> Fear lies in the unknown. Organizations have processes and procedures to defend against well-known attacks like data breaches, but they don’t know what — if anything — will stop AI-powered attacks yet.
>
> — Marcus LaFerrera, Director of SURGe, Splunk

*Image Description: Two bar charts side by side. The first shows what cyberattacks are most concerning, with AI-powered attacks at 36%, data breach at 24%, cyber extortion at 23%, and business email compromise at 21%. The second shows what cyberattacks have been experienced, with data breach at 52%, system compromise at 49%, ransomware at 48%, cyber extortion at 47%, and identity management attack at 47%.*

Human beings are the common denominator

How are bad actors getting in? Despite the rise in automation and generative AI, humans are still the weak link. Respondents name misconfigured systems as both the most common threat vector (38%) and the most concerning threat vector (35%).

This alignment between concern and experience suggests security teams know misconfiguration is a problem (kudos to monitoring!) but cannot manage it effectively. More complex systems and scarce security talent may exacerbate the issue and make eliminating misconfigurations altogether seem like a game of whac-a-mole.

*Image Description: A bar chart showing the top threat vectors, including misconfigured systems at 38%, vulnerabilities in internally developed apps at 31%, known software vulnerabilities at 29%, lateral movement at 28%, and zero-day vulnerabilities at 30%.*

Financially-motivated attacks persist

When it comes to data breaches, ransomware, and extortion — the trio of financially motivated attacks — the bogeyman is real. The number of respondents who had their data and systems held hostage rose from 35% in 2022 to 42% in 2024. And cyber extortion, a ransomware tactic that involves stealing and threatening to release company data publicly, was more common than ransomware itself. Forty-eight percent of respondents say they experienced cyber extortion, compared to 45% who were ransomware victims.

The popularity of cyber extortion may be attributed to the success of 2021’s Colonial Pipeline incident, and more recently, the MOVEit attacks in which the Russian-based ransomware group Clop anticipated earnings of $75-100 million from extortion.

As organizations realize the importance of testing backups, cybercriminals may be moving away from encryption and toward data exfiltration and extortion — techniques that involve less work, yield higher payouts, and don’t rely on failed backups.

Geopolitics inflame cyber woes

2024 has been afflicted by global unrest. These rising geopolitical tensions have cyber implications that affect even seemingly apolitical organizations. A 2023 hacktivist attack on a Pennsylvania-based water treatment plant underscores that no one is completely safe from nation-state adversaries and terrorist groups.

Eighty-six percent of respondents say the current geopolitical climate is contributing to their organization being targeted more. Technology companies in particular agree strongly with this sentiment (42%) compared to 29% of respondents overall. High-profile breaches with geopolitical ties like SolarWinds remind technology companies, particularly IT services providers, that they can be a bridge for politically motivated actors to reach a range of targets.

Interestingly, only 17% of public sector respondents strongly agree that rising geopolitical tensions make them more of a target, perhaps because government organizations have been — and likely always will be — a target for geopolitical attacks.

> “Hacktivism isn’t always sophisticated,” says Audra Streetman, security strategist at Splunk SURGe. “Politically motivated attackers often use older vulnerabilities, default passwords, and other low-hanging fruit to target organizations, so a commitment to cyber hygiene is more important than ever.”

> Growing geopolitical tensions will continue to increase risks, even to organizations that are seemingly apolitical. A byproduct of our global supply chain is the inherited risk with every digital link.
>
> — Mick Baccio, Global Security Advisor, Splunk

## The mounting pressure of compliance

For security professionals, regulatory compliance is up there with death and taxes: they can count on it. In fact, 62% say they’ve already been impacted by changing compliance mandates that require disclosure of material breaches.

Security professionals are keenly aware that the regulatory environment will trigger changes to their work in intended and perhaps unintended ways. For example, 87% agree that one year from now they will handle compliance very differently. And while compliance and cybersecurity aren’t contradictory by any means, the unintended consequences could include sacrificing one program for another. Eighty-six percent say they’ll shift budgets to prioritize compliance regulations over security best practices.

The responses echo our October 2023 CISO Report, in which 84% of CISO respondents were concerned about personal liability for cybersecurity incidents. In the same study, 84% of CISOs said their boards or governing bodies equated strong security with regulatory compliance and not with traditional security success metrics.

It’s not hard to see why. New rules in the U.S. require organizations regulated by the Securities and Exchange Commission (SEC) to disclose and describe all “material” cybersecurity incidents, and to share information on their risk management programs annually. Failing to comply could result in steep financial penalties, legal prosecution, and even jail time for executives. In the European Union, the NIS2 Directive requires organizations to establish appropriate teams to respond to incidents and information systems to exchange information. Leaders can be held personally liable for infringements.

Security professionals are caught between a metaphorical rock and a hard place. Underestimate the damage, and they can face fraud allegations and possible jail time. Overestimate, and their assumptions can cause stock prices to nosedive and breed general distrust with the board.

This poses somewhat of a moral quandary: Do you underreport a breach and hope it flies under the radar? Or overreport an incident to cover all your bases — and yourself — in the process, knowing your company share price might take a hit?

Regulation is now an undeniable mainstay of security strategy. Simulation exercises such as tabletops can help companies uncover gaps, while also proving to regulators they are invested in continuous improvement — before they become the next headline.

*Image Description: Text highlighting the consequences of new regulations to report material breaches. 63% expect that organizations will overreport breaches as material to avoid penalties, 61% predict that valuations of publicly traded organizations will decline as a result of reporting material breaches, and 26% believe both things will happen.*

Security, legal, and compliance teams join forces

Once upon a time, compliance was largely a transactional function. Compliance teams operated in silos, often without communicating with or even fully understanding the role of the security teams, and vice versa.

The dearth of regulations puts those days in the rearview as non-compliance carries more serious consequences. In October 2023, the SEC charged SolarWinds’ former CISO with fraud and internal control failures that led to the devastating 2020 cyberattack, alleging that he misled shareholders about the company’s cybersecurity practices. Communication between the board, legal, compliance, and security teams is non-negotiable, so learning to play nice together is a must.

Organizations and their boards will have to think long and hard about who is most liable when — not if — a breach occurs. That likely means the CISO. But it also could include the CTO, CIO, or even the cyber expert on the board, who could be targeted for a derivative suit or suffer additional scrutiny.

These developments are not lost on security professionals, with the majority of respondents ramping up security practices and facilitating alignment among legal and compliance teams.

Getting everyone on the same page will pay dividends. Aligning priorities, roles, and responsibilities makes your security posture more effective, while empowering legal and compliance teams to become more self-sufficient.

*Image Description: Text highlighting how security and compliance teams are working together. 90% are ramping up security training for legal and compliance teams, 91% are ramping up legal and compliance training for security teams, and 91% say everyone on their security team makes compliance a part of their jobs.*

Compliance gets personal

The SolarWinds’ indictment was a watershed moment — the first time the SEC ever charged a CISO in relation to a cybersecurity incident. This unprecedented action marked a turning point in how the world views cybersecurity, and it will have lasting implications for security leaders and their teams. Cyber risk is now unequivocally synonymous with business risk.

The SEC is holding executives and other stakeholders accountable, and they’re not holding back. Along with a spate of new, fully-enforced global mandates, security teams must also report incidents more quickly. The E.U.’s NIS2 allows 24 to 72 hours, while the SEC provides slightly more breathing room with up to four business days. Still, the window is shrinking — a development that will likely be a call to arms for the most seasoned professionals.

More accountability for incidents may lead to better security practices, but it may also have a chilling effect on the profession. How many would be willing to go to jail for making a mistake on the job?

The fear is probably overblown, but these outliers represent a real deterrent. At a time when cyber teams grapple with talent shortages, the fear of compliance penalties is one more reason to consider a different career.

*Image Description: Text highlighting that compliance pressure creates career doubt. 76% agree that the risk of personal liability is making cybersecurity a less attractive field, 70% say they’ve considered leaving the industry altogether due to job stress, and 36% say they’ve considered leaving the industry multiple times.*

## Forging ahead

In 2024, cybersecurity is guided by a medley of global dynamics, including new compliance requirements and geopolitical tensions, but there are also reasons to be hopeful. Being bold and bullish on AI will bode well for defenders — especially if organizations can mitigate the risks and maintain control over how their employees use AI tools.

Another reason for optimism moving forward is that businesses are investing more in cybersecurity. Nearly every organization surveyed (96%) says they will increase their spending on cybersecurity in the next one to two years.

*Image Description: A numbered list of the highest cybersecurity priorities over the next two years. The priorities include providing security operations training, purchasing security operations tools, developing an integrated software architecture, researching cloud-based security technologies, and increasing the use of outsourced resources.*

A bit of parting advice

With so much change and evolving technology, it can be difficult for organizations to determine where to focus their efforts. Splunk experts shared their advice with this year’s data in mind.

*   **Embrace generative AI throughout the business.** Widespread adoption is already occurring across the business (93%) and within security teams (91%). Organizations that resist generative AI may get left behind. Attempting to ban it altogether will close the door to innovation while simultaneously opening one for shadow AI.
*   **Craft thoughtful generative AI policies without sacrificing innovation.** Rushing to adopt generative AI without considering the risks and implications is a mistake. Create a policy around generative AI and develop a plan for business and security use cases to pull ahead of the 34% of organizations without a codified policy. Determine which generative AI risks are most concerning — for 49% of respondents, it’s data leakage — and build policies that address them specifically.
*   **Emphasize collaboration among teams and consolidation among tools.** Digitally resilient organizations are breaking down silos in software engineering, engineering operations, and most importantly, IT. Seventy-six percent of leading organizations increased collaboration with IT operations this year to improve digital resilience. Another way to reduce friction is tool consolidation, which can prevent dashboard overload and help teams focus on meaningful threats. Forty-three percent of respondents report that they pivot between too many disparate security tools and management consoles.
*   **Get in lockstep with legal and compliance teams.** This year ushers in a new era of compliance for security leaders, who should work closely with legal and compliance teams for maximum alignment. Ninety-one percent say security teams already make compliance part of their jobs. Organizations can lean on simulation exercises such as tabletops to help uncover security and compliance gaps, while also proving to regulators they are invested in continuous improvement.
*   **Learn how to effectively advocate for resources.** Cybersecurity maturity comes from the top down — 95% of leading organizations say they have the resources and authority to solve problems. CISOs in particular should be able to discuss and translate security risk from a business perspective to earn a seat at the table with executives. Communicate to the board in ways that highlight the business value of cybersecurity investments. This includes reporting