# An in-depth look at cybersecurity threat trends with insights into how cybercriminals are swiftly advancing and what is required to stop them.

## Table of Contents
- [Report data and methodology](#report-data-and-methodology)
- [EXECUTIVE SUMMARY](#executive-summary)
- [BIG TRENDS FOR 2023](#big-trends-for-2023)
- [THE EVOLUTION OF MALICIOUS AI](#the-evolution-of-malicious-ai)
- [BEC TYPES AND INSIGHTS](#bec-types-and-insights)
- [THE MOVE TO MOBILE AND THE GROWTH OF SMISHING](#the-move-to-mobile-and-the-growth-of-smishing)
- [INSIGHTS ON KEY FINDINGS](#insights-on-key-findings)
- [GENERATIVE AI SECURITY FOR THE WIN](#generative-ai-security-for-the-win)
- [Get a Customized Email Security Risk Assessment](#get-a-customized-email-security-risk-assessment)
- [Contact Us](#contact-us)
- [About SlashNext](#about-slashnext)

## Report data and methodology
The report data represents threats detected by SlashNext security products. SlashNext analyzed billions of link-based, malicious attachments and natural language threats scanned in email, mobile, and browser channels during a 12-month period from Q4 2022 to Q3 2023. The organizations in our sample ranged in size from 500 to 200,000 users, spanning a variety of industries in North America. The survey of 300+ cybersecurity professionals from organizations with 1,000+ employees was conducted April - May 2023 in North America.

## EXECUTIVE SUMMARY
So much has changed in cybersecurity since we last published our State of Phishing Report in 2022. Just a few months after the debut of ChatGPT in November 2022, the platform reached over 100 million users worldwide. We quickly learned that some of the most common users of large language model (LLM) chatbots are cybercriminals leveraging the tool to help write business email compromise (BEC) attacks and systematically launch highly targeted phishing attacks.

Still, people are the most vulnerable part of an organization when it comes to phishing, scams, and fraud. The launch of these generative AI chatbots has raised the stakes, enabling hackers to become more effective at spear-phishing and BEC to perpetrate cybersecurity breaches, including lucrative ransomware and data theft.

This report will highlight how phishing has changed through the lens of cybersecurity technology and cybersecurity professionals to understand better what they are experiencing and how these threats have evolved since ChatGPT launched. SlashNext Threat Labs intelligence saw a 1,265% increase in malicious phishing emails since the launch of ChatGPT at the end of 2022 and 68% of all phishing emails used text-based BEC tactics, solidifying the concerns over the use of chatbots and jailbreaks contributing to an exponential growth of phishing as more cybercriminals were able to launch sophisticated attacks quickly. Credential phishing continues a stratospheric rise with a 967% increase, driven mostly by the demand of ransomware groups looking for access to companies in exchange for money. Mobile phishing is on the rise as it’s the most unprotected of all communication channels, with 39% of mobile threats consisting of Smishing (SMS phishing).

Finally, this report will dive into some of the most pervasive threats, including the shift to multi-channel phishing, sophisticated credential theft on email, and the massive increase in threats from trusted services.

In this report, you’ll learn:
- The top trends of 2023 in phishing and message-based attacks and what this likely means for the future
- How the rise of malicious chatbots and generative AI has and will continue to change everything
- The move to mobile - Natural language attacks on mobile kick off a new multi-channel threat trend because hackers know you’re vulnerable and not protected
- Trends and insights into the growing BEC threat landscape
- What’s required to stay protected in today’s threat landscape

## BIG TRENDS FOR 2023
The big story of 2023 is generative AI, which kicked off in late 2022 with the launch of OpenAI’s ChatGPT. From the halls of the United States Congress to deep in the Dark Web, the possibilities of generative AI are only limited by our imagination.

For cybercriminals, AI chatbots like ChatGPT have lowered the barriers to creating sophisticated business email compromise (BEC) attacks and improved malware. For the infosecurity community, generative AI promises better detection, and security vendors with the foresight to develop generative AI technology are ahead of the curve. Still, much is unknown about the future of generative AI, but in this report we will explore Dark LLMs, Malicious Chatbots, Jailbreaks and how these tools have contributed to the increase in phishing to date.

People are still the most targeted and vulnerable part of any organization. The rise in multi-stage attacks between email, mobile, and collaboration tools demonstrates how cyberattacks have grown in sophistication by targeting less protected channels, like mobile. Hackers still find phishing the most effective tool to perpetrate a breach in an organization.

![Image: Phishing has increased by 1,265% from Q4-2022 to Q3-2023, equating to an average of 31k daily phishing attacks.]

In 2023, cyber threats increased rapidly. We observed a 45% increase in total malicious attacks across spear-phishing, Smishing, malware, and other social engineering attacks. Sophisticated spear phishing attacks represent the vast majority of threats. SlashNext threat intelligence saw a 1,265% increase in malicious phishing emails since Q4 2022 (Exhibit 1). The launch of ChatGPT at the end of the year is not a coincidence in the exponential growth of malicious phishing emails as the use of chatbots and jailbreaks contributed to the increase as more cybercriminals were able to launch sophisticated attacks quickly.

### Credential Phishing – The Number One Access Point to Breaches
Credential phishing continues to grow with a 967% increase (Exhibit 2), driven mostly by the demand of ransomware groups looking for access to companies in exchange for money. The volume of credential phishing campaigns spans email, mobile, social, and collaboration tools and can be broken down into three categories: Text-based BEC, linked-based, and file-based attacks. Text-based BEC attacks represent 68% of all threats found. (Exhibit 3)

![Image: Phishing has increased by 967% from Q4 2022 to Q3 2023.]

### Continuation of Trusted Services Attacks
Cybercriminals still favor using legitimate services to hide phishing and malware. The benefit of using trusted domains is that they are hard to detect with reputation-based and relationship graph threat detection, which organizations use widely to protect users.

Trusted domains give attackers more anonymity. It’s hard for users to identify these types of attacks, and taking down this malicious content is often more complex, which gives hackers more time to perpetrate these attacks.

In 2023, SlashNext detected many phishing threats hosted on legitimate infrastructure like Microsoft Sharepoint, AWS, Salesforce, and trusted services vendors. It’s important to point out that cybercriminals have increased the use of trusted services attacks because it results in successful attacks.

![Image: Text-based BEC attacks represent 68% of all phishing in 2023.]

### The Malicious Use of QR Codes
The threat of malicious QR codes has increased in 2023. Threats like QR code phishing (quishing) and QR code login jacking (QRLJacking) are exploiting user trust and convenience, and bypasses security filters. Cybercriminals are manipulating QR codes to redirect users to malicious sites to steal login credentials and financial information. These malicious QR codes can contain malware to gain access to the user’s mobile device and steal personal and financial information.

While comprehensive statistics are still emerging, security experts have noted a recent spike in QR code-based phishing attacks as cybercriminals leverage this tactic to exploit user trust and convenience. Given the growing dependence on QR codes across various sectors and the ease of manipulating them, it is highly likely that quishing attacks will continue to increase in popularity among cybercriminals.

### Generative AI - Using ChatGPT for Work or Personal Tasks
ChatGPT has set records for how incredibly fast the platform attracted new users. It reached over 100 million users worldwide in January 2023, just two months after its launch.

Just a few months later, nearly half of our survey respondents (46%) reported testing ChatGPT themselves to complete or assist in their daily tasks as security professionals. More than half (54%) also reported trying out ChatGPT in their personal lives. That disparity may indicate that people perceive the risks of generative AI to be lower in their personal lives than in their professional roles.

In digging deeper into the types of tasks cybersecurity professionals are tapping ChatGPT for, 40% of respondents said they had already used ChatGPT to write emails in personal or professional settings. It should come as no surprise then that this is one of hackers’ most common uses of ChatGPT. Cybercriminals leverage ChatGPT to help write BEC attacks and systematically launch highly targeted phishing attacks.

## THE EVOLUTION OF MALICIOUS AI
### The Discovery of WormGPT
In July 2023, researchers from SlashNext made a significant discovery related to the growing use of generative AI in BEC attacks. This BEC involved the use of OpenAI’s ChatGPT and a cybercrime tool called WormGPT.

The investigation began when one of our researchers stumbled upon a forum thread titled “Hacker’s Guide to Sending Professional Phishing Emails.” Within this thread, a user shared a technique for composing phishing emails. The process involved crafting the email in one’s native language, translating it using Google Translate, and then refining it through ChatGPT to give it a more professional tone.

At the same time, we noticed a rise in the number of malicious actors sharing “jailbreak prompts” specifically designed for ChatGPT. We will discuss this aspect in more detail shortly.

![Image: A screenshot of the ‘hacker’s guide’ to sending professional phishing emails.]

During our investigation, we discovered WormGPT, an AI chatbot equipped with a customized large language model (LLM) that helps cybercriminals with various activities, including BEC attacks.

WormGPT is built on the GPTJ language model, which was developed in 2021. It has a variety of features, including unlimited character support, chat memory retention, and code formatting capabilities. According to its creator, WormGPT is trained on a diverse range of data sources, with a specific focus on malware-related data.

Keen to understand the capabilities of WormGPT, we obtained a license and conducted our own tests. As part of our initial experiment, we provided a prompt to WormGPT.

![Image: A screenshot of the WormGPT advertisement thread.]

The results were striking, as WormGPT generated an email that was not only highly persuasive but also strategically cunning, highlighting its potential for sophisticated phishing and BEC attacks.

### The Discovery of FraudGPT
After the emergence of WormGPT, reports started circulating about another malicious chatbot called ‘FraudGPT.’ This bot was marketed as an “exclusive” tool tailored for fraudsters, hackers, spammers, and similar individuals, boasting an extensive list of features.

![Image: A screenshot of WormGPT being fed a prompt.]

![Image: A screenshot of the FraudGPT advertisement thread.]

Puzzlingly, we had not come across this during our ongoing monitoring efforts. Even after concluding our research, we continued to closely observe the cybercrime underground for emerging trends.

It appeared that the person behind FraudGPT, who operated under the alias ‘CanadianKingpin12,’ tried to advertise it on the forums and markets we monitored. However, these advertisements were quickly removed, and on one forum, their account was permanently banned due to multiple policy violations. It’s worth noting that even platforms associated with cybercrime have rules and policies in place to curb certain activities.

This suggests that the launch of FraudGPT may have faced obstacles, prompting its developers to choose more decentralized communication platforms, particularly Telegram. This theory gains credibility as many cybercrime forums and markets explicitly forbid discussions related to ‘hard fraud,’ which may have been associated with FraudGPT’s promotional approach.

During our investigation, we posed as potential buyers and managed to obtain a video showcasing some of FraudGPT’s capabilities, which was shared by the seller. One of our primary objectives was to assess whether FraudGPT surpassed WormGPT in technological prowess and overall effectiveness.

To this end, we asked CanadianKingpin12 about their opinion on WormGPT. The response strongly emphasized FraudGPT’s superiority, hinting at foundational similarities between the two.

![Image: A screenshot of CanadianKingpin12’s banned profile.]

Although CanadianKingpin12 did not explicitly admit to being the same seller for both tools, it seemed plausible because their communication revealed the potential to facilitate the sale of both products. In addition, they revealed their work on two more chatbots named DarkBART and DarkBERT, setting the stage for the next section.

### DarkBART and DarkBERT
During our investigation, we discovered that CanadianKingpin12 had developed two new chatbots called DarkBART and DarkBERT. According to their claims, both chatbots had internet access and could be integrated with Google Lens, which would allow text to be accompanied by images. However, our interactions with CanadianKingpin12 introduced an element of confusion, as their statements alternated between claims of involvement in bot development to assertions of mere access to them. The puzzle surrounding these contradictory statements unraveled when we investigated one of the mentioned bots, specifically DarkBERT.

![Image: A screenshot of CanadianKingpin12’s message revealing new bots.]

![Image: A screenshot of CanadianKingpin12 revealing new bot’s functionality.]

Our research revealed that DarkBERT is in fact a pre-trained language model developed by a company called S2W. DarkBERT underwent specialized training on a vast corpus of text from the Dark Web. It’s important to clarify that S2W’s DarkBERT primarily serves the purpose of combating cybercrime, not facilitating it.

Over time, it became evident that CanadianKingpin12 had access to DarkBERT, as they shared videos that we subsequently featured on our blog. One of these videos showed the chatbot configured for malicious purposes. Based on the available information and interactions, we concluded that CanadianKingpin12 had gained access to S2W’s DarkBERT and was using it maliciously.

S2W’s statement about access to their version of DarkBERT is contingent upon receiving an email from an academic address. This means that all someone associated with CanadianKingpin12 would need to do is obtain an academic email address (.edu or .ac.uk) and contact S2W. These email addresses can be obtained for as little as $3.00 on forums and markets associated with cybercrime.

It’s important to exercise caution here as we could not confirm this scenario with 100% accuracy. However, based on our research, it appears to be the most probable scenario.

![Image: A screenshot of S2W DarkBERT access requirements.]

### AI Jailbreaking Explored
Chatbots like ChatGPT have filters in place to ensure that their responses align with ethical policies. If a user tries to instruct ChatGPT to perform unethical or illegal actions, it immediately notifies them that it cannot do so. However, resourceful users have found ways to bypass these filters and manipulate ChatGPT and similar chatbots using specific prompts.

Jailbreak prompts can take various forms, ranging from simple commands to creative narratives aimed at coaxing the chatbot into disregarding its limitations. The ultimate objective is to find language that convinces the AI to unleash its full, uncensored potential.

During our exploration of these jailbreak prompts, we came across entire communities sharing various prompts to manipulate chatbots, such as ChatGPT, into compliance. We tested some of these prompts and verified their effectiveness.

![Image: A screenshot of a jailbroken ChatGPT session.]

![Image: A screenshot of a jailbreak community.]

### The Surrounding Scams
As we monitored cybercrime forums and markets, we noticed an interesting trend emerging in relation to the developments involving WormGPT, FraudGPT, DarkBERT, DarkBART, and AI jailbreaks.

Firstly, we observed that entire sections were being filled with users and threads looking for WormGPT and FraudGPT.

Secondly, we noticed a multitude of different malicious AI chatbot variants surfacing.

Thirdly, we observed that a number of scam websites on the clear web began to appear, offering WormGPT for sale.

![Image: A screenshot of users on a forum asking where they can find WormGPT.]

![Image: A screenshot of the discussion surrounding malicious AI variants.]

Based on these trends, our conclusion was as follows: Other cybercriminals had recognized an opportunity to target users seeking WormGPT and FraudGPT, leading them to create numerous variants for sale. Many of these variants had claimed to utilize private or custom language models in their advertisements. However, it had seemed highly unlikely that all these users, including novice cybercriminals, could have developed custom chatbots and made them available for sale within a few weeks.

After reviewing discussions about these variants, a common allegation had emerged, suggesting that they resembled jailbroken ChatGPT sessions. Upon conducting further research, it had become evident that these allegations had merit. The chatbot variants in question had borne striking similarities to jailbroken ChatGPT sessions. This discovery had raised intriguing questions about their true nature.

![Image: A screenshot of an example WormGPT scam website.]

![Image: A screenshot of EscapeGPT’s author admitting it’s a wrapper.]

They admitted that most of these variants are, indeed, wrappers designed to connect to jailbroken versions of ChatGPT. This revelation sheds light on the primary benefit of these variants, which is anonymity. Customers can access an anonymous, unauthenticated interface by making cryptocurrency payments, allowing them to exploit AI-generated content for malicious purposes without revealing their true identities.

While we closely monitor some of these variants, it became apparent that most of them fell short of the initial WormGPT discovered in terms of technological sophistication.

In our assessment, WormGPT is the only chatbot that employs a custom LLM. Although we cannot confirm this with absolute certainty, it remains our conclusion based on all the available information.

### Our Future Predictions
For many years, cybercriminals have had access to basic text generation tools. However, the introduction of AI has ushered in a new era in this field. The rapid growth of AI-powered tools offered by authors and sellers on cybercrime forums and markets underscores this advancement. There are now dedicated cybercrime forum sections focusing on the malicious use of AI.

While some in the cybersecurity industry may remain skeptical about the impact of AI on cybercrime, the concerns are not unfounded. Companies in the cybersecurity sector often highlight emerging threats, and in the case of AI, the potential dangers are real.

There are likely numerous malicious use cases of AI that have yet to be fully explored in the context of cybercrime. ChatGPT and similar AI systems have already had a significant impact on the daily lives of law-abiding citizens, and cybercriminals are well aware of their potential.

We predict that AI-powered threats will continue to rise. Cybercriminals will discover new ways to exploit AI, including for sophisticated phishing campaigns. Since our initial report on WormGPT, AI has remained in the spotlight. While the full extent is still uncertain, AI does appear to be opening a new chapter in the evolution of cybercrime. We believe it deserves serious attention from the industry and the public, while avoiding exaggerated rhetoric. As with any technology, the prudent approach is to monitor it carefully and respond promptly to real dangers.

## BEC TYPES AND INSIGHTS
Our 2023 survey of cybersecurity and IT professionals reinforced widespread security concerns about phishing attacks, especially BEC attacks. According to the FBI IC3 Report, the average cost of a successful BEC attack is $174,000. In SlashNext’s survey of cybersecurity professionals, 46% reported receiving a BEC attack. The diversity and sophistication of BEC types have received a significant boost from the public availability of generative AI chatbots. (Exhibit 4)

### Clever Payroll Diversion Attacks
Payroll diversion attacks are a specific type of attack that involve a cybercriminal redirecting an employee’s paycheck into their own account. The payroll diversion attacks are often successful because many organizations cannot detect these types of attacks, so bad actors are reaching the human resources or payroll manager who has the authority to make the requested change. In the below example, the attacker intends to build trust by asking for additional information. The cybercriminal impersonated an employee, and the request was sent to the payroll manager. The attacker used a Gmail account to avoid domain/IP reputation filtering.

![Image: Types of Natural Language BEC Threats.]

### Multi-Stage Invoice Fraud is Getting Creative
A growing multi-stage trend observed by SlashNext is cybercriminals sending spear phishing attacks impersonating coworkers’ communications. Below is an example of a multi-channel attack that includes Invoice Fraud and Executive Impersonation. The attacker impersonated a vendor and the COO, and the request was sent to the accounts payable manager. The attacker used a Salesforce lookalike domain. The attacker faked instructions from the COO to pay the invoice. The accounting manager responds and requests the invoices.

![Image: Example of a BEC Payroll Diversion.]

![Image: Example of a BEC Invoice Fraud.]

## THE MOVE TO MOBILE AND THE GROWTH OF SMISHING
Mobile phishing is on the rise as it’s also the most unprotected of all communication channels, with 39% of mobile threats consisting of Smishing (Exhibit 5). Most threats on mobile start with SMS text messaging. Scams and executive impersonation phishing delivered through text use familiar credential stealing, malware, and exploit tactics but are customized for mobile delivery.

As the threat landscape grows, everyone is a potential target of cybercriminals. We found that 77% of infosec professionals reported being the targets of phishing attacks themselves. As the survey and SlashNext Labs intelligence confirmed, phishing still happens in email. However, our research also confirms the growth of phishing threats expanding outside of email, with 28% coming from text messages. (Exhibit 6)

![Image: Smishing represents 39% of all mobile phishing threats in 2023.]

Another big trend involved mobile impersonation scams of legitimate businesses or services. It’s noteworthy that 87% of our survey respondents confirmed that they have opted in to receive text message alerts from their banks, wireless service providers, airlines, and other providers. This means they are accustomed to receiving communications from trusted service providers in this manner, providing ample opportunities for cybercriminals to execute credential phishing and scams by imitating popular brands and service providers and luring victims into clicking a link or calling a phone number.

In 2023, SlashNext Labs intelligence shows mobile credential phishing made up 41% of all mobile threats, and scams were 12% of all mobile threats. Mobile is a threat vector we expect to continue to expand in the next 12 months.

![Image: 28% of InfoSec Pros report receiving phishing via text message in 2023.]

## INSIGHTS ON KEY FINDINGS
Generative AI is already used maliciously to automate thousands of uniquely tailored phishing messages and variations of those messages, increasing the threat actor’s success rate. Such emails reflect similar emotions and urgency as the originals but with slightly altered wording, making it hard to identify bots as the senders.The results in the report highlight how much the threat landscape has changed since 2022.

The launch of generative AI chatbots and the quick adoption of the technology by the cybercrime community is driving the change as demonstrated in the 1,265% increase in malicious emails. With 68% of all phishing emails using text-based BEC tactics, CISOs will need to ensure their email security can detect these sophisticated zero-hour threats.

Two important stats from the report to continue to watch are the growth in Smishing and the growth of BEC attacks. As 28% of phishing is happening via text message in 2023, we expect to see that grow in 2024. The FBI IC3 report estimates $6.9 billion in losses, led by phishing and business email compromise.

Our survey of infosec professionals revealed the growth of multi-channel phishing, malware and exploits. All survey participants reported being the targets of phishing attacks outside of email, with 10% coming from collaboration tools and 23% happening in social media. To protect users and the organization from an expensive breach it will be important to ensure protection exists in collaboraton tools and on mobile devices.

Finally, the one thing that is certain is the future of generative AI is still largely unknown. The rapid growth of these tools on cybercrime forums and markets highlights how cybercriminals have embraced the technology and that the potential threat is real. Fortunately there are cybersecurity vendors who have introduced generative AI technologies which are used to detect and stop malicious generative AI attack attempts.

## GENERATIVE AI SECURITY FOR THE WIN
The availability of AI for malicious intent combined with how people work today (remote and hybrid environments, multiple devices and communication channels, etc.) will expose users to more cyberattacks, increasing the chance of more breaches for organizations. Organizations now require solutions that use generative AI to defend against advanced BEC, supply chain attacks, executive impersonation, and financial fraud. Generative AI security solutions are extremely effective because they can detect how threat actors play off human emotions, such as requests that ask users to take quick actions based on fear or trust. Generative AI can simulate those same human emotions and behaviors in its detection process.

SlashNext’s complete generative AI messaging security solution detects, predicts, and stops spear phishing, BEC, Smishing, and other zero-hour social engineering attacks in email, mobile, and web messaging apps. SlashNext Generative AI mimics human threat researchers by combining natural language processing, computer vision, and machine learning with relationship graphs and deep contextualization to thwart sophisticated multi-channel messaging attacks. The system is purpose-built to anticipate the vast numbers of AI-generated BEC threats by using AI data augmentation and cloning technologies to assess a core threat and then spawn thousands of other versions of that same core threat, which enables the system to train itself on possible variations.

![Image: SlashNext GenAI protects users across 30K email, mobile and web messaging apps.]

The SlashNext solution is patent pending and has been under development internally for over two years. SlashNext is at the forefront of multi-channel messaging security, and its threat researchers recognized that generative AI would soon change the face of BEC attacks.

SlashNext CompleteTM Generative AI features include:
- BEC Generative AI Augmentation – Auto generates thousands of new BEC variants from today’s threats to stop tomorrow’s attacks.
- Relationship Graphs & Contextual Analysis – A baseline of known-good communication patterns and writing styles for each employee and supplier to detect unusual communications and conversation styles.
- Natural Language Processing – Analyzes text in email body and attachments for topic, tone emotion, intent, and manipulation triggers associated with social engineering tactics.
- Computer Vision Recognition – Leverages SlashNext’s LiveScanTM to inspect URLs in real-time for any visual deviations such as image and layouts to detect credential phishing web pages. For instance, SlashNext GenAI uses computer vision to detect extremely subtle deviations from imposter Microsoft 365 log-in page and blocks access.
- File Attachment Inspection – Analyzes social engineering traits of attachments and malicious codes to stop ransomware.
- Sender Impersonation Analysis – Evaluates headline details and email authentication results to stop impersonation attacks.

## Get a Customized Email Security Risk Assessment
See if your organization’s current email security stops the latest Business Email Compromise (BEC), malicious attachments, and malicious exploits by plugging into SlashNext Cloud Email Security in observability mode.

Deploy in minutes with no impact on your existing email infrastructure or mail flow. Receive a customized report detailing the attacks missed by your current email security.
- Fast and Easy: With one click, deploy in minutes a read-only API integration with no impact on your existing email infrastructure. We will analyze your current email for security threats and deliver a customized report of attacks.
- Actionable Insights: The customized report provides a clear and insightful view of your organization’s email security. Our goal is to offer data-driven insights to make informed decisions, fortify your cybersecurity measures, and ensure your organization’s protection.
- Comprehensive Summary: Receive a summary of the impact on your organization and where your current security defenses stand today. See how you can improve security readiness and save valuable SOC time and operating expenses.

For more information visit https://slashnext.com/risk-assessment/

## Contact Us
6701 Koll Center Parkway, Suite 250
Pleasanton CA 94566
Contact Sales 1(800) 930-8643
Request a Demo https://www.slashnext.com/request-a-demo/

## About SlashNext
SlashNext CompleteTM AI Security for Email, Mobile and Browser
At SlashNext, we know that the demands of a changing and growing threat landscape increase the need to protect people where they work in real time. That’s why SlashNext Complete delivers zero-hour protection for how people work today across email, mobile, and browser apps. With SlashNext’s generative AI to defend against advanced business email compromise, Smishing, spear phishing, executive impersonation, and financial fraud, your people are always protected anywhere they work. Request a demo today. slashnext.com/request-a-demo/
